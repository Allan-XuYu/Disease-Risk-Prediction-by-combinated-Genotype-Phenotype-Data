{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "jewish-frost",
   "metadata": {},
   "source": [
    "# This is a copy for self-learning for [Computing polygenic scores using LDpred2](https://privefl.github.io/bigsnpr/articles/LDpred2.html#downloading-genotype-data-and-summary-statistics-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "animated-bahrain",
   "metadata": {},
   "source": [
    "Note that most of the algorithms of this package don’t handle **missing values**. You can use snp_fastImpute() (taking a few hours for a chip of 15K x 300K) and snp_fastImputeSimple() (taking a few minutes only) to impute missing values of genotyped variants."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "colonial-rover",
   "metadata": {},
   "source": [
    "## Downloading genotype data and summary statistics\n",
    "You can download data and unzip files in R. We store those files in a directory called \"tmp-data\" here.\n",
    "\n",
    "You can see there how we generated these data from the 1000 Genomes project. Note that these data are for educational purposes only, not for use as a reference panel.\n",
    "\n",
    "First, you need to read genotype data from the PLINK files (or BGEN files) as well as the text file containing summary statistics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "brown-boxing",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading required package: bigstatsr\n",
      "\n"
     ]
    }
   ],
   "source": [
    "library(bigsnpr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "olive-atlantic",
   "metadata": {},
   "source": [
    "+ Self-dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "furnished-treasurer",
   "metadata": {},
   "outputs": [],
   "source": [
    "path <- \"C:\\\\data\\\\tmp-data\\\\\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "homeless-control",
   "metadata": {},
   "outputs": [
    {
     "ename": "ERROR",
     "evalue": "Error: File 'C:\\data\\tmp-data\\public-data.bk' already exists.\n",
     "output_type": "error",
     "traceback": [
      "Error: File 'C:\\data\\tmp-data\\public-data.bk' already exists.\nTraceback:\n",
      "1. snp_readBed(\"C:\\\\data\\\\tmp-data\\\\public-data.bed\")",
      "2. assert_noexist(paste0(backingfile, \".bk\"))",
      "3. stop2(\"File '%s' already exists.\", file)",
      "4. stop(sprintf(...), call. = FALSE)"
     ]
    }
   ],
   "source": [
    "snp_readBed(\"C:\\\\data\\\\tmp-data\\\\public-data.bed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "identical-genre",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List of 3\n",
      " $ genotypes:Reference class 'FBM.code256' [package \"bigstatsr\"] with 15 fields\n",
      "  ..and 26 methods, of which 12 are  possibly relevant:\n",
      "  ..  add_columns, as.FBM, bm, bm.desc, check_dimensions,\n",
      "  ..  check_write_permissions, copy#envRefClass, initialize, initialize#FBM,\n",
      "  ..  save, show#envRefClass, show#FBM\n",
      " $ fam      :'data.frame':\t559 obs. of  6 variables:\n",
      "  ..$ family.ID  : chr [1:559] \"EUR_GBR\" \"EUR_GBR\" \"EUR_GBR\" \"EUR_GBR\" ...\n",
      "  ..$ sample.ID  : chr [1:559] \"HG00096\" \"HG00097\" \"HG00099\" \"HG00100\" ...\n",
      "  ..$ paternal.ID: int [1:559] 0 0 0 0 0 0 0 0 0 0 ...\n",
      "  ..$ maternal.ID: int [1:559] 0 0 0 0 0 0 0 0 0 0 ...\n",
      "  ..$ sex        : int [1:559] 1 2 2 2 1 2 1 2 2 1 ...\n",
      "  ..$ affection  : int [1:559] 1 2 1 1 1 1 2 1 2 1 ...\n",
      " $ map      :'data.frame':\t130816 obs. of  6 variables:\n",
      "  ..$ chromosome  : int [1:130816] 2 2 2 2 2 2 2 2 2 2 ...\n",
      "  ..$ marker.ID   : chr [1:130816] \"rs13400442\" \"rs7594567\" \"rs7597758\" \"rs13\"..\n",
      "  ..$ genetic.dist: int [1:130816] 0 0 0 0 0 0 0 0 0 0 ...\n",
      "  ..$ physical.pos: int [1:130816] 18506 21833 22398 28228 32003 32005 36787 5..\n",
      "  ..$ allele1     : chr [1:130816] \"C\" \"G\" \"T\" \"A\" ...\n",
      "  ..$ allele2     : chr [1:130816] \"T\" \"C\" \"C\" \"G\" ...\n",
      " - attr(*, \"class\")= chr \"bigSNP\"\n"
     ]
    }
   ],
   "source": [
    "obj.bigSNP <- snp_attach(\"C:\\\\data\\\\tmp-data\\\\public-data.rds\")\n",
    "# See how the file looks like\n",
    "str(obj.bigSNP, max.level = 2, strict.width = \"cut\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "interested-technical",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'data.frame':\t130816 obs. of  10 variables:\n",
      " $ chromosome  : int  2 2 2 2 2 2 2 2 2 2 ...\n",
      " $ marker.ID   : chr  \"rs13400442\" \"rs7594567\" \"rs7597758\" \"rs13383216\" ...\n",
      " $ physical.pos: int  18506 21833 22398 28228 32003 32005 36787 55237 56916 61687 ...\n",
      " $ allele1     : chr  \"C\" \"G\" \"T\" \"A\" ...\n",
      " $ allele2     : chr  \"T\" \"C\" \"C\" \"G\" ...\n",
      " $ beta        : num  -0.073 0.0439 -0.3325 -0.5445 -0.4881 ...\n",
      " $ beta_se     : num  0.277 0.248 0.192 0.247 0.242 ...\n",
      " $ n_case      : int  157 157 157 157 157 157 157 157 157 157 ...\n",
      " $ n_control   : int  402 402 402 402 402 402 402 402 402 402 ...\n",
      " $ p           : num  0.7925 0.8593 0.0846 0.028 0.0439 ...\n"
     ]
    }
   ],
   "source": [
    "# Get aliases for useful slots\n",
    "G   <- obj.bigSNP$genotypes\n",
    "CHR <- obj.bigSNP$map$chromosome\n",
    "POS <- obj.bigSNP$map$physical.pos\n",
    "y   <- obj.bigSNP$fam$affection - 1\n",
    "NCORES <- nb_cores()\n",
    "# Read external summary statistics\n",
    "sumstats <- bigreadr::fread2(paste(path,\"public-data-sumstats.txt\",sep=''))\n",
    "str(sumstats)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "capable-villa",
   "metadata": {},
   "source": [
    "We split genotype data using part of the data to choose hyper-parameters and another part of the data to evaluate statistical properties of polygenic risk score such as AUC. Here we consider that there are 400 individuals to be used as validation set to tune hyper-parameters for LDpred2-grid. The other 159 individuals are used as test set to evaluate the final models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "young-better",
   "metadata": {},
   "outputs": [],
   "source": [
    "set.seed(1)\n",
    "ind.val <- sample(nrow(G), 400)\n",
    "ind.test <- setdiff(rows_along(G), ind.val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "distant-entry",
   "metadata": {},
   "source": [
    "## Matching variants between genotype data and summary statistics\n",
    "To match variants contained in genotype data and summary statistics, the variables \"chr\" (chromosome number), \"pos\" (genetic position), \"a0\" (reference allele) and \"a1\" (derived allele) should be available in the summary statistics and in the genotype data. These 4 variables are used to match variants between the two data frames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "imported-alignment",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "130,816 variants to be matched.\n",
      "\n",
      "18,932 ambiguous SNPs have been removed.\n",
      "\n",
      "Some duplicates were removed.\n",
      "\n",
      "111,866 variants have been matched; 0 were flipped and 0 were reversed.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sumstats$n_eff <- 4 / (1 / sumstats$n_case + 1 / sumstats$n_control)\n",
    "sumstats$n_case <- sumstats$n_control <- NULL\n",
    "names(sumstats) <- c(\"chr\", \"rsid\", \"pos\", \"a0\", \"a1\", \"beta\", \"beta_se\", \"p\", \"n_eff\")\n",
    "map <- obj.bigSNP$map[-(2:3)]\n",
    "names(map) <- c(\"chr\", \"pos\", \"a0\", \"a1\")\n",
    "info_snp <- snp_match(sumstats, map)\n",
    "#info_snp <- snp_match(sumstats, map, strand_flip = FALSE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "angry-relationship",
   "metadata": {},
   "source": [
    "## Computing LDpred2 scores for one chromosome\n",
    "Some quality control on summary statistics is highly recommended (see paper).\n",
    "\n",
    "#### Correlation\n",
    "First, you need to compute correlations between variants. We recommend to use a window size of 3 cM (see ref)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "competitive-phoenix",
   "metadata": {},
   "outputs": [],
   "source": [
    "POS2 <- snp_asGeneticPos(CHR, POS, dir = path, ncores = NCORES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "hollywood-sheffield",
   "metadata": {},
   "outputs": [],
   "source": [
    "## indices in info_snp\n",
    "ind.chr <- which(info_snp$chr == 2)         \n",
    "df_beta <- info_snp[ind.chr, c(\"beta\", \"beta_se\", \"n_eff\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "adapted-novelty",
   "metadata": {},
   "outputs": [],
   "source": [
    "## indices in G\n",
    "ind.chr2 <- info_snp$`_NUM_ID_`[ind.chr]    \n",
    "corr0 <- snp_cor(G, ind.col = ind.chr2, ncores = NCORES, \n",
    "                 infos.pos = POS2[ind.chr2], size = 3 / 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "floral-frame",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp <- tempfile(tmpdir = path)\n",
    "if (packageVersion(\"bigsnpr\") >= package_version(\"1.4.9\") &&\n",
    "    packageVersion(\"bigsparser\") >= package_version(\"0.4.0\")) {\n",
    "  corr <- as_SFBM(corr0, tmp)\n",
    "} else {\n",
    "  corr <- bigsparser::as_SFBM(as(corr0, \"dgCMatrix\"), tmp)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "automated-jacket",
   "metadata": {},
   "source": [
    "Here, we have built the LD matrix using variants from one chromosome only. In practice, you need to build it for variants from all chromosomes. Please look at the code linked at the beginning.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "headed-panic",
   "metadata": {},
   "source": [
    "## Infinitesimal model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "viral-novelty",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       ".dl-inline {width: auto; margin:0; padding: 0}\n",
       ".dl-inline>dt, .dl-inline>dd {float: none; width: auto; display: inline-block}\n",
       ".dl-inline>dt::after {content: \":\\0020\"; padding-right: .5ex}\n",
       ".dl-inline>dt:not(:first-of-type) {padding-left: .5ex}\n",
       "</style><dl class=dl-inline><dt>int</dt><dd>1</dd><dt>h2</dt><dd>0.0975846128116684</dd></dl>\n"
      ],
      "text/latex": [
       "\\begin{description*}\n",
       "\\item[int] 1\n",
       "\\item[h2] 0.0975846128116684\n",
       "\\end{description*}\n"
      ],
      "text/markdown": [
       "int\n",
       ":   1h2\n",
       ":   0.0975846128116684\n",
       "\n"
      ],
      "text/plain": [
       "       int         h2 \n",
       "1.00000000 0.09758461 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "(ldsc <- snp_ldsc2(corr0, df_beta))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "interpreted-barrel",
   "metadata": {},
   "outputs": [],
   "source": [
    "h2_est <- ldsc[[\"h2\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "convinced-substance",
   "metadata": {},
   "outputs": [],
   "source": [
    "beta_inf <- snp_ldpred2_inf(corr, df_beta, h2 = h2_est)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "young-preservation",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       ".dl-inline {width: auto; margin:0; padding: 0}\n",
       ".dl-inline>dt, .dl-inline>dd {float: none; width: auto; display: inline-block}\n",
       ".dl-inline>dt::after {content: \":\\0020\"; padding-right: .5ex}\n",
       ".dl-inline>dt:not(:first-of-type) {padding-left: .5ex}\n",
       "</style><dl class=dl-inline><dt>Mean</dt><dd>0.668863919833695</dd><dt>2.5%</dt><dd>0.575416027062046</dd><dt>97.5%</dt><dd>0.759200278754982</dd><dt>Sd</dt><dd>0.0474585869420211</dd></dl>\n"
      ],
      "text/latex": [
       "\\begin{description*}\n",
       "\\item[Mean] 0.668863919833695\n",
       "\\item[2.5\\textbackslash{}\\%] 0.575416027062046\n",
       "\\item[97.5\\textbackslash{}\\%] 0.759200278754982\n",
       "\\item[Sd] 0.0474585869420211\n",
       "\\end{description*}\n"
      ],
      "text/markdown": [
       "Mean\n",
       ":   0.6688639198336952.5%\n",
       ":   0.57541602706204697.5%\n",
       ":   0.759200278754982Sd\n",
       ":   0.0474585869420211\n",
       "\n"
      ],
      "text/plain": [
       "      Mean       2.5%      97.5%         Sd \n",
       "0.66886392 0.57541603 0.75920028 0.04745859 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pred_inf <- big_prodVec(G, beta_inf, ind.row = ind.test, ind.col = ind.chr2)\n",
    "AUCBoot(pred_inf, y[ind.test])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "colored-entity",
   "metadata": {},
   "source": [
    "## Grid of models\n",
    "In practice, we recommend to test multiple values for h2 and p."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "sublime-pride",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       ".list-inline {list-style: none; margin:0; padding: 0}\n",
       ".list-inline>li {display: inline-block}\n",
       ".list-inline>li:not(:last-child)::after {content: \"\\00b7\"; padding: 0 .5ex}\n",
       "</style>\n",
       "<ol class=list-inline><li>0.0683</li><li>0.0976</li><li>0.1366</li></ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 0.0683\n",
       "\\item 0.0976\n",
       "\\item 0.1366\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 0.0683\n",
       "2. 0.0976\n",
       "3. 0.1366\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "[1] 0.0683 0.0976 0.1366"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "(h2_seq <- round(h2_est * c(0.7, 1, 1.4), 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "settled-cycling",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       ".list-inline {list-style: none; margin:0; padding: 0}\n",
       ".list-inline>li {display: inline-block}\n",
       ".list-inline>li:not(:last-child)::after {content: \"\\00b7\"; padding: 0 .5ex}\n",
       "</style>\n",
       "<ol class=list-inline><li>1e-04</li><li>0.00018</li><li>0.00032</li><li>0.00056</li><li>0.001</li><li>0.0018</li><li>0.0032</li><li>0.0056</li><li>0.01</li><li>0.018</li><li>0.032</li><li>0.056</li><li>0.1</li><li>0.18</li><li>0.32</li><li>0.56</li><li>1</li></ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 1e-04\n",
       "\\item 0.00018\n",
       "\\item 0.00032\n",
       "\\item 0.00056\n",
       "\\item 0.001\n",
       "\\item 0.0018\n",
       "\\item 0.0032\n",
       "\\item 0.0056\n",
       "\\item 0.01\n",
       "\\item 0.018\n",
       "\\item 0.032\n",
       "\\item 0.056\n",
       "\\item 0.1\n",
       "\\item 0.18\n",
       "\\item 0.32\n",
       "\\item 0.56\n",
       "\\item 1\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 1e-04\n",
       "2. 0.00018\n",
       "3. 0.00032\n",
       "4. 0.00056\n",
       "5. 0.001\n",
       "6. 0.0018\n",
       "7. 0.0032\n",
       "8. 0.0056\n",
       "9. 0.01\n",
       "10. 0.018\n",
       "11. 0.032\n",
       "12. 0.056\n",
       "13. 0.1\n",
       "14. 0.18\n",
       "15. 0.32\n",
       "16. 0.56\n",
       "17. 1\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       " [1] 0.00010 0.00018 0.00032 0.00056 0.00100 0.00180 0.00320 0.00560 0.01000\n",
       "[10] 0.01800 0.03200 0.05600 0.10000 0.18000 0.32000 0.56000 1.00000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "(p_seq <- signif(seq_log(1e-4, 1, length.out = 17), 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "placed-wound",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"dataframe\">\n",
       "<caption>A data.frame: 102 × 3</caption>\n",
       "<thead>\n",
       "\t<tr><th scope=col>p</th><th scope=col>h2</th><th scope=col>sparse</th></tr>\n",
       "\t<tr><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;lgl&gt;</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><td>0.00010</td><td>0.0683</td><td>FALSE</td></tr>\n",
       "\t<tr><td>0.00018</td><td>0.0683</td><td>FALSE</td></tr>\n",
       "\t<tr><td>0.00032</td><td>0.0683</td><td>FALSE</td></tr>\n",
       "\t<tr><td>0.00056</td><td>0.0683</td><td>FALSE</td></tr>\n",
       "\t<tr><td>0.00100</td><td>0.0683</td><td>FALSE</td></tr>\n",
       "\t<tr><td>0.00180</td><td>0.0683</td><td>FALSE</td></tr>\n",
       "\t<tr><td>0.00320</td><td>0.0683</td><td>FALSE</td></tr>\n",
       "\t<tr><td>0.00560</td><td>0.0683</td><td>FALSE</td></tr>\n",
       "\t<tr><td>0.01000</td><td>0.0683</td><td>FALSE</td></tr>\n",
       "\t<tr><td>0.01800</td><td>0.0683</td><td>FALSE</td></tr>\n",
       "\t<tr><td>0.03200</td><td>0.0683</td><td>FALSE</td></tr>\n",
       "\t<tr><td>0.05600</td><td>0.0683</td><td>FALSE</td></tr>\n",
       "\t<tr><td>0.10000</td><td>0.0683</td><td>FALSE</td></tr>\n",
       "\t<tr><td>0.18000</td><td>0.0683</td><td>FALSE</td></tr>\n",
       "\t<tr><td>0.32000</td><td>0.0683</td><td>FALSE</td></tr>\n",
       "\t<tr><td>0.56000</td><td>0.0683</td><td>FALSE</td></tr>\n",
       "\t<tr><td>1.00000</td><td>0.0683</td><td>FALSE</td></tr>\n",
       "\t<tr><td>0.00010</td><td>0.0976</td><td>FALSE</td></tr>\n",
       "\t<tr><td>0.00018</td><td>0.0976</td><td>FALSE</td></tr>\n",
       "\t<tr><td>0.00032</td><td>0.0976</td><td>FALSE</td></tr>\n",
       "\t<tr><td>0.00056</td><td>0.0976</td><td>FALSE</td></tr>\n",
       "\t<tr><td>0.00100</td><td>0.0976</td><td>FALSE</td></tr>\n",
       "\t<tr><td>0.00180</td><td>0.0976</td><td>FALSE</td></tr>\n",
       "\t<tr><td>0.00320</td><td>0.0976</td><td>FALSE</td></tr>\n",
       "\t<tr><td>0.00560</td><td>0.0976</td><td>FALSE</td></tr>\n",
       "\t<tr><td>0.01000</td><td>0.0976</td><td>FALSE</td></tr>\n",
       "\t<tr><td>0.01800</td><td>0.0976</td><td>FALSE</td></tr>\n",
       "\t<tr><td>0.03200</td><td>0.0976</td><td>FALSE</td></tr>\n",
       "\t<tr><td>0.05600</td><td>0.0976</td><td>FALSE</td></tr>\n",
       "\t<tr><td>0.10000</td><td>0.0976</td><td>FALSE</td></tr>\n",
       "\t<tr><td>...</td><td>...</td><td>...</td></tr>\n",
       "\t<tr><td>0.00100</td><td>0.0976</td><td>TRUE</td></tr>\n",
       "\t<tr><td>0.00180</td><td>0.0976</td><td>TRUE</td></tr>\n",
       "\t<tr><td>0.00320</td><td>0.0976</td><td>TRUE</td></tr>\n",
       "\t<tr><td>0.00560</td><td>0.0976</td><td>TRUE</td></tr>\n",
       "\t<tr><td>0.01000</td><td>0.0976</td><td>TRUE</td></tr>\n",
       "\t<tr><td>0.01800</td><td>0.0976</td><td>TRUE</td></tr>\n",
       "\t<tr><td>0.03200</td><td>0.0976</td><td>TRUE</td></tr>\n",
       "\t<tr><td>0.05600</td><td>0.0976</td><td>TRUE</td></tr>\n",
       "\t<tr><td>0.10000</td><td>0.0976</td><td>TRUE</td></tr>\n",
       "\t<tr><td>0.18000</td><td>0.0976</td><td>TRUE</td></tr>\n",
       "\t<tr><td>0.32000</td><td>0.0976</td><td>TRUE</td></tr>\n",
       "\t<tr><td>0.56000</td><td>0.0976</td><td>TRUE</td></tr>\n",
       "\t<tr><td>1.00000</td><td>0.0976</td><td>TRUE</td></tr>\n",
       "\t<tr><td>0.00010</td><td>0.1366</td><td>TRUE</td></tr>\n",
       "\t<tr><td>0.00018</td><td>0.1366</td><td>TRUE</td></tr>\n",
       "\t<tr><td>0.00032</td><td>0.1366</td><td>TRUE</td></tr>\n",
       "\t<tr><td>0.00056</td><td>0.1366</td><td>TRUE</td></tr>\n",
       "\t<tr><td>0.00100</td><td>0.1366</td><td>TRUE</td></tr>\n",
       "\t<tr><td>0.00180</td><td>0.1366</td><td>TRUE</td></tr>\n",
       "\t<tr><td>0.00320</td><td>0.1366</td><td>TRUE</td></tr>\n",
       "\t<tr><td>0.00560</td><td>0.1366</td><td>TRUE</td></tr>\n",
       "\t<tr><td>0.01000</td><td>0.1366</td><td>TRUE</td></tr>\n",
       "\t<tr><td>0.01800</td><td>0.1366</td><td>TRUE</td></tr>\n",
       "\t<tr><td>0.03200</td><td>0.1366</td><td>TRUE</td></tr>\n",
       "\t<tr><td>0.05600</td><td>0.1366</td><td>TRUE</td></tr>\n",
       "\t<tr><td>0.10000</td><td>0.1366</td><td>TRUE</td></tr>\n",
       "\t<tr><td>0.18000</td><td>0.1366</td><td>TRUE</td></tr>\n",
       "\t<tr><td>0.32000</td><td>0.1366</td><td>TRUE</td></tr>\n",
       "\t<tr><td>0.56000</td><td>0.1366</td><td>TRUE</td></tr>\n",
       "\t<tr><td>1.00000</td><td>0.1366</td><td>TRUE</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A data.frame: 102 × 3\n",
       "\\begin{tabular}{lll}\n",
       " p & h2 & sparse\\\\\n",
       " <dbl> & <dbl> & <lgl>\\\\\n",
       "\\hline\n",
       "\t 0.00010 & 0.0683 & FALSE\\\\\n",
       "\t 0.00018 & 0.0683 & FALSE\\\\\n",
       "\t 0.00032 & 0.0683 & FALSE\\\\\n",
       "\t 0.00056 & 0.0683 & FALSE\\\\\n",
       "\t 0.00100 & 0.0683 & FALSE\\\\\n",
       "\t 0.00180 & 0.0683 & FALSE\\\\\n",
       "\t 0.00320 & 0.0683 & FALSE\\\\\n",
       "\t 0.00560 & 0.0683 & FALSE\\\\\n",
       "\t 0.01000 & 0.0683 & FALSE\\\\\n",
       "\t 0.01800 & 0.0683 & FALSE\\\\\n",
       "\t 0.03200 & 0.0683 & FALSE\\\\\n",
       "\t 0.05600 & 0.0683 & FALSE\\\\\n",
       "\t 0.10000 & 0.0683 & FALSE\\\\\n",
       "\t 0.18000 & 0.0683 & FALSE\\\\\n",
       "\t 0.32000 & 0.0683 & FALSE\\\\\n",
       "\t 0.56000 & 0.0683 & FALSE\\\\\n",
       "\t 1.00000 & 0.0683 & FALSE\\\\\n",
       "\t 0.00010 & 0.0976 & FALSE\\\\\n",
       "\t 0.00018 & 0.0976 & FALSE\\\\\n",
       "\t 0.00032 & 0.0976 & FALSE\\\\\n",
       "\t 0.00056 & 0.0976 & FALSE\\\\\n",
       "\t 0.00100 & 0.0976 & FALSE\\\\\n",
       "\t 0.00180 & 0.0976 & FALSE\\\\\n",
       "\t 0.00320 & 0.0976 & FALSE\\\\\n",
       "\t 0.00560 & 0.0976 & FALSE\\\\\n",
       "\t 0.01000 & 0.0976 & FALSE\\\\\n",
       "\t 0.01800 & 0.0976 & FALSE\\\\\n",
       "\t 0.03200 & 0.0976 & FALSE\\\\\n",
       "\t 0.05600 & 0.0976 & FALSE\\\\\n",
       "\t 0.10000 & 0.0976 & FALSE\\\\\n",
       "\t ... & ... & ...\\\\\n",
       "\t 0.00100 & 0.0976 & TRUE\\\\\n",
       "\t 0.00180 & 0.0976 & TRUE\\\\\n",
       "\t 0.00320 & 0.0976 & TRUE\\\\\n",
       "\t 0.00560 & 0.0976 & TRUE\\\\\n",
       "\t 0.01000 & 0.0976 & TRUE\\\\\n",
       "\t 0.01800 & 0.0976 & TRUE\\\\\n",
       "\t 0.03200 & 0.0976 & TRUE\\\\\n",
       "\t 0.05600 & 0.0976 & TRUE\\\\\n",
       "\t 0.10000 & 0.0976 & TRUE\\\\\n",
       "\t 0.18000 & 0.0976 & TRUE\\\\\n",
       "\t 0.32000 & 0.0976 & TRUE\\\\\n",
       "\t 0.56000 & 0.0976 & TRUE\\\\\n",
       "\t 1.00000 & 0.0976 & TRUE\\\\\n",
       "\t 0.00010 & 0.1366 & TRUE\\\\\n",
       "\t 0.00018 & 0.1366 & TRUE\\\\\n",
       "\t 0.00032 & 0.1366 & TRUE\\\\\n",
       "\t 0.00056 & 0.1366 & TRUE\\\\\n",
       "\t 0.00100 & 0.1366 & TRUE\\\\\n",
       "\t 0.00180 & 0.1366 & TRUE\\\\\n",
       "\t 0.00320 & 0.1366 & TRUE\\\\\n",
       "\t 0.00560 & 0.1366 & TRUE\\\\\n",
       "\t 0.01000 & 0.1366 & TRUE\\\\\n",
       "\t 0.01800 & 0.1366 & TRUE\\\\\n",
       "\t 0.03200 & 0.1366 & TRUE\\\\\n",
       "\t 0.05600 & 0.1366 & TRUE\\\\\n",
       "\t 0.10000 & 0.1366 & TRUE\\\\\n",
       "\t 0.18000 & 0.1366 & TRUE\\\\\n",
       "\t 0.32000 & 0.1366 & TRUE\\\\\n",
       "\t 0.56000 & 0.1366 & TRUE\\\\\n",
       "\t 1.00000 & 0.1366 & TRUE\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A data.frame: 102 × 3\n",
       "\n",
       "| p &lt;dbl&gt; | h2 &lt;dbl&gt; | sparse &lt;lgl&gt; |\n",
       "|---|---|---|\n",
       "| 0.00010 | 0.0683 | FALSE |\n",
       "| 0.00018 | 0.0683 | FALSE |\n",
       "| 0.00032 | 0.0683 | FALSE |\n",
       "| 0.00056 | 0.0683 | FALSE |\n",
       "| 0.00100 | 0.0683 | FALSE |\n",
       "| 0.00180 | 0.0683 | FALSE |\n",
       "| 0.00320 | 0.0683 | FALSE |\n",
       "| 0.00560 | 0.0683 | FALSE |\n",
       "| 0.01000 | 0.0683 | FALSE |\n",
       "| 0.01800 | 0.0683 | FALSE |\n",
       "| 0.03200 | 0.0683 | FALSE |\n",
       "| 0.05600 | 0.0683 | FALSE |\n",
       "| 0.10000 | 0.0683 | FALSE |\n",
       "| 0.18000 | 0.0683 | FALSE |\n",
       "| 0.32000 | 0.0683 | FALSE |\n",
       "| 0.56000 | 0.0683 | FALSE |\n",
       "| 1.00000 | 0.0683 | FALSE |\n",
       "| 0.00010 | 0.0976 | FALSE |\n",
       "| 0.00018 | 0.0976 | FALSE |\n",
       "| 0.00032 | 0.0976 | FALSE |\n",
       "| 0.00056 | 0.0976 | FALSE |\n",
       "| 0.00100 | 0.0976 | FALSE |\n",
       "| 0.00180 | 0.0976 | FALSE |\n",
       "| 0.00320 | 0.0976 | FALSE |\n",
       "| 0.00560 | 0.0976 | FALSE |\n",
       "| 0.01000 | 0.0976 | FALSE |\n",
       "| 0.01800 | 0.0976 | FALSE |\n",
       "| 0.03200 | 0.0976 | FALSE |\n",
       "| 0.05600 | 0.0976 | FALSE |\n",
       "| 0.10000 | 0.0976 | FALSE |\n",
       "| ... | ... | ... |\n",
       "| 0.00100 | 0.0976 | TRUE |\n",
       "| 0.00180 | 0.0976 | TRUE |\n",
       "| 0.00320 | 0.0976 | TRUE |\n",
       "| 0.00560 | 0.0976 | TRUE |\n",
       "| 0.01000 | 0.0976 | TRUE |\n",
       "| 0.01800 | 0.0976 | TRUE |\n",
       "| 0.03200 | 0.0976 | TRUE |\n",
       "| 0.05600 | 0.0976 | TRUE |\n",
       "| 0.10000 | 0.0976 | TRUE |\n",
       "| 0.18000 | 0.0976 | TRUE |\n",
       "| 0.32000 | 0.0976 | TRUE |\n",
       "| 0.56000 | 0.0976 | TRUE |\n",
       "| 1.00000 | 0.0976 | TRUE |\n",
       "| 0.00010 | 0.1366 | TRUE |\n",
       "| 0.00018 | 0.1366 | TRUE |\n",
       "| 0.00032 | 0.1366 | TRUE |\n",
       "| 0.00056 | 0.1366 | TRUE |\n",
       "| 0.00100 | 0.1366 | TRUE |\n",
       "| 0.00180 | 0.1366 | TRUE |\n",
       "| 0.00320 | 0.1366 | TRUE |\n",
       "| 0.00560 | 0.1366 | TRUE |\n",
       "| 0.01000 | 0.1366 | TRUE |\n",
       "| 0.01800 | 0.1366 | TRUE |\n",
       "| 0.03200 | 0.1366 | TRUE |\n",
       "| 0.05600 | 0.1366 | TRUE |\n",
       "| 0.10000 | 0.1366 | TRUE |\n",
       "| 0.18000 | 0.1366 | TRUE |\n",
       "| 0.32000 | 0.1366 | TRUE |\n",
       "| 0.56000 | 0.1366 | TRUE |\n",
       "| 1.00000 | 0.1366 | TRUE |\n",
       "\n"
      ],
      "text/plain": [
       "    p       h2     sparse\n",
       "1   0.00010 0.0683 FALSE \n",
       "2   0.00018 0.0683 FALSE \n",
       "3   0.00032 0.0683 FALSE \n",
       "4   0.00056 0.0683 FALSE \n",
       "5   0.00100 0.0683 FALSE \n",
       "6   0.00180 0.0683 FALSE \n",
       "7   0.00320 0.0683 FALSE \n",
       "8   0.00560 0.0683 FALSE \n",
       "9   0.01000 0.0683 FALSE \n",
       "10  0.01800 0.0683 FALSE \n",
       "11  0.03200 0.0683 FALSE \n",
       "12  0.05600 0.0683 FALSE \n",
       "13  0.10000 0.0683 FALSE \n",
       "14  0.18000 0.0683 FALSE \n",
       "15  0.32000 0.0683 FALSE \n",
       "16  0.56000 0.0683 FALSE \n",
       "17  1.00000 0.0683 FALSE \n",
       "18  0.00010 0.0976 FALSE \n",
       "19  0.00018 0.0976 FALSE \n",
       "20  0.00032 0.0976 FALSE \n",
       "21  0.00056 0.0976 FALSE \n",
       "22  0.00100 0.0976 FALSE \n",
       "23  0.00180 0.0976 FALSE \n",
       "24  0.00320 0.0976 FALSE \n",
       "25  0.00560 0.0976 FALSE \n",
       "26  0.01000 0.0976 FALSE \n",
       "27  0.01800 0.0976 FALSE \n",
       "28  0.03200 0.0976 FALSE \n",
       "29  0.05600 0.0976 FALSE \n",
       "30  0.10000 0.0976 FALSE \n",
       "... ...     ...    ...   \n",
       "73  0.00100 0.0976 TRUE  \n",
       "74  0.00180 0.0976 TRUE  \n",
       "75  0.00320 0.0976 TRUE  \n",
       "76  0.00560 0.0976 TRUE  \n",
       "77  0.01000 0.0976 TRUE  \n",
       "78  0.01800 0.0976 TRUE  \n",
       "79  0.03200 0.0976 TRUE  \n",
       "80  0.05600 0.0976 TRUE  \n",
       "81  0.10000 0.0976 TRUE  \n",
       "82  0.18000 0.0976 TRUE  \n",
       "83  0.32000 0.0976 TRUE  \n",
       "84  0.56000 0.0976 TRUE  \n",
       "85  1.00000 0.0976 TRUE  \n",
       "86  0.00010 0.1366 TRUE  \n",
       "87  0.00018 0.1366 TRUE  \n",
       "88  0.00032 0.1366 TRUE  \n",
       "89  0.00056 0.1366 TRUE  \n",
       "90  0.00100 0.1366 TRUE  \n",
       "91  0.00180 0.1366 TRUE  \n",
       "92  0.00320 0.1366 TRUE  \n",
       "93  0.00560 0.1366 TRUE  \n",
       "94  0.01000 0.1366 TRUE  \n",
       "95  0.01800 0.1366 TRUE  \n",
       "96  0.03200 0.1366 TRUE  \n",
       "97  0.05600 0.1366 TRUE  \n",
       "98  0.10000 0.1366 TRUE  \n",
       "99  0.18000 0.1366 TRUE  \n",
       "100 0.32000 0.1366 TRUE  \n",
       "101 0.56000 0.1366 TRUE  \n",
       "102 1.00000 0.1366 TRUE  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "(params <- expand.grid(p = p_seq, h2 = h2_seq, sparse = c(FALSE, TRUE)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "adjusted-melbourne",
   "metadata": {},
   "outputs": [],
   "source": [
    "# takes several minutes if you do not have many cores\n",
    "beta_grid <- snp_ldpred2_grid(corr, df_beta, params, ncores = NCORES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "supposed-vacation",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_grid <- big_prodMat(G, beta_grid, ind.col = ind.chr2)\n",
    "params$score <- big_univLogReg(as_FBM(pred_grid[ind.val, ]), y[ind.val])$score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "finite-pleasure",
   "metadata": {},
   "outputs": [],
   "source": [
    "library(ggplot2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "deluxe-orlando",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA0gAAANICAMAAADKOT/pAAAAilBMVEUAAAAAujgaGhozMzNN\nTU1UVFRhnP9oaGh3d3d8fHyDg4OMjIyNjY2VlZWXl5eampqfn5+jo6Onp6evr6+ysrK2tra5\nubm8vLy9vb3BwcHCwsLHx8fIyMjJycnOzs7Q0NDR0dHY2NjZ2dne3t7h4eHk5OTp6enq6urr\n6+vv7+/w8PD19fX4dm3///8eZFs4AAAACXBIWXMAABJ0AAASdAHeZh94AAAgAElEQVR4nO2d\ni3qcOBKFIUvwuB3HYzvXyST2OLHj2PD+r7fNXRIlIYHUFOicb3fSXVYdqRF/I4SgkxKCoMVK\n1m4ABO1BAAmCPAggQZAHASQI8iCABEEeBJAgyIMAEgR5EECCIA8CSBDkQQAJgjwIIEGQBwEk\nCPIggARBHgSQIMiDABIEeRBAgiAPAkgQ5EEACYI8CCBBkAcBJAjyIIAEQR4EkCDIgwASBHlQ\nNCAlCfFR766yY/zi2+mbA+1MMYP06yxpld2t0SRoR4oYpF+JIC8kPVwdmbz6ZYjdnSfJ2Zf2\nzU2WZDft62/HP5x/KX1psiW/rvqGCFth3MYQDan0oesN+YNLdXttSGhFDNJxVJd9eynLly/V\n+O5peRV3BJRy7KJ5c16/OR+9bt+coCXtm7PqUw8cZaM2hmhIG29eyB9cqttrQ4IrXpC+DX30\ndCTpZpThrCy5eilfrpr9kYp9SM6P380PZ8mH45ub5Kb+S1Xxl+Ts4XiUOE88ff9OteR4MP7y\nUm0CcS+9Sx7UNgZpSNnwVb+QP7hUt9+GBFe8IB2/8B6613eJ2tUzdJdctcYPdOwlSV6qN7/q\nyrL6zUv9+qw5IP7y0Aqrlly1xN4Ih4qneo+V2xiiIWXFSNb2hvTBpbr9NiS84gKpHnXfvAwB\n6a9GFUUxUaLbK++Eo5sU+yYd9toapYonW1EpTdOlLWkgruC56guc1zvsN4dDc57nMxpS1X72\npHzS+q1Ut0tDOCgqkC60MwuTIBXFJEkXSXNO/Su5oGPdm0Zn7RHpbAj9sjkhSNNJkiZb0n/a\nocIvyTexmIXyfJIkqiHHSr+oXxnNB5fqdmgIC8UEUsfReGbh+AV5QWZ1Koppkoa9M6FjZ0k9\nWXbeDHOar9wb4bToLrPYedJ0mqTJlnRvXoYCWQO03EaT8nyaJKohRKD94FLd9g3hoZhASrLj\nGfbLl2Q8s3Cjmf8udKJrUF+Mdt92Equpvp4szHqOjphn2r0m1UnzWSdactV+3C999EsbUdo4\nVq6TbUNGgf6DS3VPNoSZYgIpaw5EH0ZTqscD0hmRIsjLEenYhA8v9fdvtd88NQfIi+7oeHFx\nZnNh2MsR6aGuqf5OaaNZ1v1VbKNJ3o5I/QeX6rZvCA/FBFL75f80OiE6n76MZHGOZAFS04J6\nLuup+Rq+y7Kh6l82e43FOdJkS6pDcH2y2EX72QCpjWZZnCNZDu3aDy7V7dAQFooJpKfhpfSn\nc5uFDdOzdtZnJu3oqmFG2lEeLGcblrbkWNPxQ1/9Krsjcdcaw64/1vSsnS1IzQfXb6wNaBut\n9CCBHgUkK44sdNGS+iTNlQmx8+kdxc9eM9mSTg/dm/5izbnX/ZeslLSv3kt1+21IeG2jlR6k\nBckXR8fhUvOt/iBdvRFiN90xsdptJZC66zqe9prJlnT60I6fHvrDotTGIA1p7ZsPKn1wqW6/\nDQmv2EF6OvPF0XGQ1nztXgiGUqzbXesTkvN2R6kHNd1Kg29+TggmW9Ltv2ftv+1FpFJpY5CG\nNGq7QPrgUt1+GxJekYN0lyWZh+WqjSbX2p3XO8WxzqdqRzm7O+7FD/Vp9q9m2srqQpKPltw0\n69guunVswtVPsY1hGlKr7QL5g0t1+21IcMUN0k2SnL94q+KLuHCiX5UpxJ7OhDftxFnzhatb\nJR2qJe2i6+7MpR9hKW0M0pBSfC19cKluvw0JrqhBOvd8ue+uujR09dBWMo4dd6yzerKsVnXh\nXnqT3Xj78p1sSdWQ834flU7NxDYGaYj0Wv7gUt1eGxJaMYPkbZoBgiIG6QIcQd4UL0jd6LzT\nim2Dtq9o9p8RSOcACfKnaPafEUgJQIL8CfsPBHkQQIIgDwJIEORBAAmCPAggQZAHASQI8iCA\nBEEeBJAgyIMAEgR5EECCIA8CSBDkQQAJgjwIIEGQBwEkCPIggARBHgSQIMiDABIEeRBAgiAP\nAkgQ5EEACYI8CCBBkAcBJAjyIIAEQR4EkCDIgwASBHkQQIIgDwJIEORBAAmCPAggQZAHASQI\n8iC/IP0POqHQCesrFEgP0MmkBWnthkUkgLQDAaT1BZB2IIC0vgDSDgSQ1hdA2oEA0voCSDsQ\nQFpfAGkHAkjrCyDtQABpfQGkHQggrS+AtAMBpPUFkHYggLS+ANIOBJDWF0Ci9EZUF3z75q1Q\nQMm4PRxLnr3/h8hXi/rXbkEabcfhzV/DtpYSyLQTCCBRojri4/Hlx6GAVP7z267wYZwvFw2h\nGEHqewMgMRa19f968/7NX3SBf9+8qb8ff3x82xQ5Ve+12i1IjYStObz8fBwC/KP8dQDpBK1S\nBJAoET3x73Fg9/bNv2SBd29uu5dn9fckQPIpEqRqq79XQwCJmYie+PvN3/X/qQLCu4/14A4g\n+ZQGpB/NOStAWqgf78+G0/vjpvv81/EM9Kb948d3b6s//tv98f2b6utLSnl4uBEytGR0evvm\nR9d1RPEfcmpUIIXsCDU0RQ1Acta/3fl9fZA4nnk2787qLjt0J5rtKPrdm6r/5JTjSU+t5rxn\nCqSPdbm/uukGucBfb/76IZWOCaSgHaGGxL/+iyOSD7178+648/646edp3h738eOXYdUdN2/O\nPj/07x7qv/1QU45/PBb65692ok3SuCcONUIfu8Jygc/VbnDzzxCICaSgHfHQpFEvq9kfNQSQ\n3KUeQt42o4f6ZP+s+QI8DsXeNH/8e5zy8c1Z8+KvN58J814PolM9wBvX/vCx+Yo9e/9xlH+K\nTl0VpKAdoRbvX/778ezN2x8jM2L62+GjLNGGQbqV3rVD7I9v3knh5r//jFPedd32ufliU8yV\nfrhpC71v61H758ftX+KIJi6QAnaEkNy+HPT2s/pXgDRDx7PWt+9uu1OTN93EdD8f8OPzzeGt\nfKSXUs7edE7dN6Kg0ebvvlr/aQtT/fPPTXViXX9NxjS0C9oRD2Lag7Sy4Wb8Vwzt5qg5jz37\nWzm+169+vH8rfB/1fxRTjF9aauizUPgzVaAv2AzcYwIpaEc8SGndyx9/dQPIB4C0XP9Uc6jt\nmFzuvx/VkeFwPPtXt6uQ4gTSO6Hwu1GB8cWNqEAK2REPclr/8q9h3SNA8qAfH98306b9lZwf\n1fjg3ZuDOCcgbdcu5a0YVKX2xHCh6AdhKZ0lx3cdqVKojhCSpZf/vu2Xax3eDNOl/zQzfwBp\nhv5t99x2vuxjNbTqNuRn+guqTjno5oiIjFvhNPh9faIsFfhbmLhtTqKiA+khUEc8KGn9y89v\nusmMbv6n0t/EjPiJtFmQunVv3ViqPVGtZwWGAUD9onsrpXzsvtI+EtcvlJ44k770RqQcBzA9\naH/V3RoTSEE74kFMk17+3Z6tHjukP186HqfG61hPpM2C9L6+8Fed3VfXJo7j6+qq3uez+nvq\nUK80qJaqvBHn0OSU5jpgdVXwn5G53BP/DKu+67x/1AIfj7vPx+oS48ezZj+KCaSgHVGLBGk4\nTXr35u1NhdI/N90XGkByUXvhprtm/r55V3+p/dv+6bhff34QtquU8u9ZV+rhQd328rv3w31I\nD/2YRTpB/tjfj/TX+DqS5BVE6w7tQnbEgxISXv7bD+6GqaD3XamTbv5a2wWpuSn10N/dVV0S\nfdfu8f8et+3b9/8eR9LyWmwxpVkr+fZdv9hSkPzu7dsH9e2on26rayVv31ErGySvIFr5HClg\nR6gh8a+33eDu4Z/3FZn9PbMAab7WOJjzEYvJhkbRdgRA2oEA0voCSDsQQFpfAGkHAkjrCyDt\nQABpfe0EpLjFCKRoBZB2IIC0vgDSDgSQ1hdA2oEA0voCSDsQQFpfwUCCTih0wvoKBZIaeKZK\nWQeXZQewXFbQuqRdNVqQVmiLU3BHlgApcDZAisMSIAXOBkhxWAKkwNkAKQ5LgBQ4GyDFYQmQ\nAmcDpDgsAVLgbIAUhyVACpwNkOKwBEiBswFSHJYAKXA2QIrDEiAFzgZIcVgCpMDZACkOS4AU\nOBsgxWEJkAJnA6Q4LOeC9Jhl4tvvl9nh6yvp69IabZDdFgdIPoI7spwL0qUE0nVW6fCH8nVp\njTbIbosDJB/BHVnOBOk+E0G6z67/lK+fslvK16U12iC7LQ6QfAR3ZDkPpNdMOiJdZvWoTgwB\nJFNBgLQ7y3kg3WbKOVKt7ED5urRGG2S3xQGSj+COLGeB9HgcxI1A+nOd/Uf5urRGG2S3xQGS\nj+COLGeBVA3lVJCOJ00/O89Kz9DJpAVp7YZFpDkg3Wf3pQrS7+vb7PBzeI8jkqkgjki7s5wB\n0mt2WY5AquLX2SPh69IabZDdFgdIPoI7spwB0m3NCzHZ8Du7JnxdWqMNstviAMlHcEeWM0DK\neo3/Qvi6tEYbZLfFAZKP4I4sAVLgbICkDxZF4b2eDYHUSMTo0FyQ/Zl9InxdWqMNAiRTcKMg\nFQVJ0jb3FC8gfc+ujyQ9HrLfhK9La7RBgGQKbhOkoqBJ2uaeshSk5p9m0Wr2nfJ1aY02CJBM\nQYDkK3ttkMr7yyy7fRT+DJBMBQFSCZDsBJBMBQFSJZwjWQggmQoCpEoAyUIAyVQQIB1V1DEM\n7cwCSKaCAKkhCCBNaucg5Xm+pBqA1IM0JmmbewpAmhPMc5IkgKQPpmkqvS/6gipJ29xTANKM\nYJ7TJAEkbTBNZZKKNlgCJLMAkskxOpDSVCap6IPliKRt7ikAaUYw7zWzmlhBSkV25Hdi0SWV\nAyRjkBdIwzmSBJP1eVO0IElvBrAKteSCygGSMcgMpFLhp4fKbrgXH0gyH8UQqoLisUodAzpX\nDpCMQWYg5WpMN9gDSK3GHElwFUIEING+Lq3RBq0LLrzAMxekUjsDAZAqpWKwH8kNxIihRSDZ\n9z9AMgWXXuBZDpLNBETcIBVUQZmkcoQSVQ+xUs+h/8ng/POzfYG0eF7aLpgbIZ6egIgOpFQI\nFnRB9TCl7NJEPcSaV03/Wx+mFhwNAdKMIA2S2F/mCYiYQSp0BYtRUNynx/VQtzPRowLrw5Rm\nXAmQfFhSQQ1ISlA/AREbSKkQdABJRMkJJHnb2+8UAKnXSc6RcutsgFQpFYKFvmBBBemBXl2c\nusFWczgCSM4FTzFrB5DcggJIxtVABW1Zzz2M9+9iTNJxS5NnSKntMAXnSJ2q6bTQR6TcIRvn\nSB1HddC8PlUDEn2kKLpZuwElTcekqfURqT7y4YhUsgOpKI49WMR9REqF4MRC70JjSYBUCCVb\nlHI6O22GKen0Fb5uSsRm6n3nINWzAKxAcnguwf5BmryHr6CC1IIHBbnqbU5b9hMdI5K0JVWS\nYgWJIMknSJovPjLYgjS/QdsHqV+7YPPkLQ1I/blLy1IxGgQO21gZVgrnZypJhqantgUH7Qqk\ndhaAD0gtSeMWRQOSyJHF4xkKKliKs3ap9LL7+3EATZ1hicPKiiSpH5R6xLlFmaRoQZq/31oE\nNSMITbDZfcYkxQaSZoxLbLBpy6LsD08dSXlTR6ksG1KvQqVSPyjHLjmYagtqgnsCqT95YQNS\nt1uMSIoFJOmA5Ack6R6MhqRu48q1CKdUAx5CPxiOXaVEEkBabjkOuoA0DFRUkqICqehlkU1P\nzgwliXXiw6YVqyGPKQJJxmNXaV5VQQR3CdLskdR0kD6npYPSFG1pGp87xdiDJBwUei6sH/Nt\nnuYU/tQfkoQNK4CkOcvpi0v1jI9dYjQ2kIRZAH4glfLc3Z5B6nfRIhX2e8urAOYn66sPd6iO\nGrk4K94pNcy71VMOUj26YVxKxHRN3ydIc09JvIKkXl7U3D/gHGMOkjCQm5z7cgRpvLCuoUK4\n+bZJThULoZ52LDg5CBT+EhlI0slLKJBy24LUghfdia5jbBsglTZXY0wYSiTUS3wMC1T7+bvm\nwQ+d02A6pFXDzVysw4R72tU92fRoQZo4pxUkXlG3B4lay5yTJV1jWwHJYn0A1S/VoirBqH5Z\nITN1E5/w7BSxLaV4OtQM+6rktp72rb5Fqe0NBbsBSRlzTU2Smc9pRYldYyZhEqQyJ6OOMdYg\nFUW/aeeBpO63tVu9YjEXS5B3R1CPTilEtcV6k3I0Chy1KLW8CSNSkMzntKKkvrEHibpNrRxI\n2idIwwxdabf0cxyT8cgpkSUbkTcUjfs6VbKFP45alFuuHd8LSKMxl3m2OTRI2p7JdSuctw9S\nIX15WN2MoAVpmhnyFhVLkLoBW7UovC8j/SvWYnc3E0CaqEfsm4nZgiFIPiinbZduYebGQSqU\nz7wMJCpKlVVD5J15RFen45FhIYxKhRrS5n+TTd8JSONDhQEkapPp6yEPSOYGGQfdeaGZ6dgi\nSNJgTixpd5+pxTlSH7VLJ5+nRWzuhqS0VFkSd4t2ar0qN7aNBiTt+kThIG61ZoU8IC0Aqcyt\nj4bsQWo+yOizLACJvFlck71gizUktd3aVyjOSfTRqvsbooyXxfYBEnWoIHf7Qh7I2/w2T9rv\nF7YgaR+UMzSCIml7IGk+CPngAztL+8dhWFvSQflsqqWmmR4s6n+7j1atkkjzYaXskC8bbhgk\n8SBMlcxHJYmJTuPTOCqlw5DfEqSCiEnKmwuCdPZ0bLyb8gKJfoKI1cUYl8dhWLeSDI6mJfL+\nyV1iU9tPmBdiYkl9xu2CJPahGaTqO6VQB8rdhpjY7YX7+CdXnaaWP5tV1P2l7oNzrmu1YgUS\nOXPm8lMd64BUDjOGUrAjSfio0i0cnTYLkvjJ6ENFP/KtPjPZ3c2fjfX0zwhNJ0FqLadBEvpr\n+AyzpuNbrXyONN1Ay18YcLr52L6Vtt9HdCsbkMQ39WgvIpDK4WxxtBxY3BKmqYHhgRjKLf/a\nPdzirEvtr2KQWnQDINk00A4kt5uP7VtpO0LWtLL+jKPD1B5B0u3hHUjdF8hYnZW2HgEk+VqC\nbg+3OfPRjyA2B9Ki73rF0uUOFadW2gf1A1Clt8Z9vVmQhF1Pe6hoRk/UrqfE+nMtdcmJYGkF\nUjH6lqM+jW4AMQ0S/dTR1c6R6NkZ4tyjnAbJYWG9WytdgtopEbW7Rt+ZmwWpmz0w3cSdNwdw\n6itSiQ2LjOVVkINlPvlADPKARH9EegAxeY6kew42J5BSpWT3SZtZMb2lw3pgx1b6sRx/8cmB\nrYJU9MFCD1KaN3s2MRxWL3bURzb1a1O8QzIvJZLGO1A1giyshnZ1dPTNV1/aNGX37R1ZrgRS\nQQRTuWSu8KG9vcV69ZVzKz1ZGr4Dam0UJGHBWq6bdxNu59dYKiSpIEk7bi5GqB2onc+Zankf\nJcc5xD2gXQX6uhmB1Fy4Fg9CSrrm0XLWi0bcW+nLcuIWt22CJC6hzqXZgu44U/2re/zmEJMv\nyJlAyqUItQMVNEn6nZf8jlPvC22bkxqHleuARKy+7TiifhaiK0kxM3mJDiBpK3YLyjHxpp7m\n8/X3bKXtSVEb0s+oNh3dr7bK2wUiAknS45hyIjaov7dZeU6B5tMYQBJJ6ptjepRHJS4gDRyZ\nLr6OR3H6wbl7cHcgPYdTIb7JxWA7GTcUyp81qjv7mPDc/Nt6VAsOqr/V71KiFin4LAcrjnQl\n6DaQ0eHTtbtkOumoBcm6KTNUjCJNO9tWGzLVP5rKMpK5mRs8IsnLToVlUcKstrJ4aGRJDOTU\nCXVpGDca70mzAF27nsW3hk9jPvMWlvHXHNHJolY5Io3uUOzuNZk6IpW+Lhmd9og0cdzcHkjy\n1VMJhB6koYwZpFLa7cVrvOL+awapv6zbBycuOA1RTdd0ra9uKEsndslaa4A0ume+/9Q0R3K6\nOOSemg9zCwZk03gmtz2Q5KD04dpFUOIU/yRIwm4vXRSVJm7FWsSLtGK6P5C6nTTNaZRYgiQ8\naYnkSEnP+4XeUwvwHIMAyRgc7WRtUOmFalGdcqmMXpkvDj8UkvpgPgxAxldpn8U3XbtGQc2n\noUcLo6Nu3l01njjPXQOkQgkKHFl2a94uebCqGyBpK3YLjoY9bVBZ0UMstCFBysWLHPLgrhSe\nGtgPQMYLh0YHH+miiunKrRTVXT+pT9SGxTbGH/bhAJLEkWW3as6l+IJkvNq1MZCUa6/qDk6t\nWBv3bK7Ape72hXDiXBLrrwaQZI5Iy3kgVSufpMU2xiuWpwdJnvBROHICaUNHpB2BpN6FNxpy\nESvWRiCNry2pu32hnDkTJD3LeXNB0i+NKZRdUl1sI2ptkMTr2tp6dgCSaSHTpkBSDjXUAtPx\nyk8VJGrqVb3OOl7xIHu2l32HgG4ueD5I48d25XTBcgWQ5JlTlSOA5FEhQBpxRCwwJbKls9+c\n3B2V3V6aP9eBJM3NjUAy/7gO2TfqYXO0lC0fH0sbrQdS/YUitNBQD9ExWztH2glIBEfCmk59\ntgiSbkvIu714wzgF0ugOp9FFlcFycuclyc4bV+p8jwFIIkfpmCPrbrWZJ3cNBgXJcLPHNkAi\nbjHQrIsj+6sP6s8Wxd2+XTknViQbBgcp7VYQjkjKqd1vLZCU7aAfe7pUA5A0vpqKXYLUTW8O\nI+wOJNtfhx+WKnQ1KYYqSOpFlZGjsZXj73GRI/rXTOTYiUGSD0hRgaT/jFsAib4Nmz4gGUCa\nuKzZX2cd3YA+tqQPSCSbc0BqIwaQ5M/CAyTDtKJLNQBJ46up2CGoeZ4ByRFpmU/c5jyYPI/n\ntElLkiPS0mLnVU/Ru5YyBUloEM0Rm70+hKXuPHDLIHUFp9a20YPAUcF2t1dvQJ/euO4gKXN+\n8hzC0FLbIe1qIJUkR3z2+gCWWwaJfjBIP4UwdduC5myKGLBVQdmNuAt0lK1/mFd/5VYNK7Pn\nEkji8/M0B+JVz5GkBqWjw6i2HoA0S/5n7VR1ICn36ywAiXrcUDGeg1azDSDRz5MfPx9MWA+g\nPoeS+ODrztrRIJkXA7pUwxwk3bWyjYBEDdiagtO3di8Cafo5WQUVNDimqQkkmaMqZvGEr1OC\nJDenA2nU6vnVACSNL9katyD1QM/2MqvNU3ts58nHO3hp8eRGE0i9Y5oK/BAodeuYFI7q2PQT\nvlYDKW2DU/d5uFTDHSTNVfENg6QsTzFYWq5EmQVSQQUVR/KgVIoDv7xbbcMdJOWA1ASnJkSd\nqgFIGl+6NU5BEiRyHLZoiwcDiapJLFL2H4fcJdXKAdKqltsFiXoybrvn2R2RbLf4jHMkzcMp\njY6jklWh+vNoTuQKKijodCApLWlAsjn93BFI9K0iWwUp133ZL9ri5F5vfJbwBEi0I3Xsqh/O\noDnj4wpSM7u/4EYIgDSpbYKkD2qGV+qdhpaOFEiVdFMnE9WcDKTRAWnhjRDbBIm8nX6zIOlG\nTaG2OH1U8AaSeY6eK0hL7ygCSJPyCNLoBrey+Sg2Zx+GoGuDqJ15asylc3QFaWIEeSqQ1MNy\nuvQeV4A0qVOAdOItTuzMJwPJPDl4EpDGcy7p4pvFNwoS9cix7YKUnnyLj3bmyXlpnSPVN+Zd\ncnWQiMlLgCSIP0jUutH6gHT6La4uYvAJ0tRVY9MCihOARF1OSxc/dWGrIAk3XXfaLEiahdVh\nt/iwJz2XY46WgTQRYwnS0qcuAKRJ7RMk+WbYk4JkWmS+Dkj1gowt7PUAqRJ1b10zsltniw93\nzVosy9Y5zgFJf//gSudIMYM0PhRvFSTtzafBt3jfoLhAGt+WFTNIpruUAZJlsB1rmu/2MzvO\nAkn/MJbTgKTGUmqEo69nTyAR05XcQaKeP9KO7Fbb4s18/OlB0j6MZRWQmt+b2cBeH8ByPyDp\nn3R1ii2uuf0cIJnqAUiztGuQNLdWBAdJ91QjgHRqy82dI5GnBauDpLnZLzqQiAv8+np2BdLm\nZu0okDqOIgRJ83iwNUBqf5JzE3v9KSwB0ozgeiCRCw9Pcx1JiQEkWbxBIi+d5MYfejjJFl/r\nHAkgsbXcHkj9AWnNLb7OrF1dMx+QqNty9PVw2usDWAKkwNm+QaIeqbQCSO0BaaN7fQBL1iCR\n6zT7kV2sII2PhgBpfcvNgTQckCIGSSEJIK1vCZACZ/sGiZoxPMVtFEoMICnvNwiS4XeXXYIA\nyaVeBaSOo43u9QEsOYNE3RQqHJAAUieAtL4lQAqc7Ruklc6RANJEcHsgpePgrHq2ChJxDQsg\nrW/JGCTqCVTiASlWkMbBk4PUc7TRvT6A5eZASsfBefUAJJd6AdJEcC5Ij1kmvr2/zrLLe9LX\npTVSECDxAUlZ4geQvIF0KYF0xKjSNeXr0hoxSD7uGiBRQYC0vuVMkO4zEaSv2fWf40HqkH0n\nfF1aIwYpkCSOAFKnU4M0cLTRvT6A5TyQXjPpiHRoXv/ODoSvS2vEIECyrgYgrW85D6TbTDlH\naiTEFoNE/iQQQCKDAGl9y1kgPWa3JQnSJeHr0hohSIEkcwSQOgGk9S1ngXSZvVIg/WzPkf5X\n6XmhCiKWP6dLbXcpLUi+KlA6o+qF3Jf3TjQHpPvsvqRAuhxOkRYfkcif8MIRiQ4GPyLJz1wR\nDkgbPXwEsJwB0ms9ghuDdJv9oXxdWjMEKZAUjgBSJ4C0vuUMkG6zx5IA6Wv2k/R1ac0QBEgO\n1QCk9S1ngJT1EqMyR0tBIn8LDyBpggBpfUtPIL1eHx41vi6t6YMUSCpHAKnTaUESOdroXh/A\ncvaiVel49Odw+CP/GSCZCm4MJPlJyQCJCnoB6fVwUP+8DCTyRyXzlAhaW84vCJAA0nRwKUj1\nP5/Ggz3/II0OSACpE0Ba39ILSMRZE0AyFdwySBJHG93rA1jyvLGPBEnlCCB1AkjrW7IEifyd\nB4CkDQKk9S03A9J4ZAeQOgGk9S23A9KII4DUKTBI0s+PyhxtdK8PYMkRJPKXhwCSPgiQ1rfk\nBxL9E17EyA4gdQJI61uyA4n8Mbw8Jw5IAKkTQFrfkhtI5M+z5gDJGDwhSHU3AKRtglRzpP4c\nu72lJgiQbOtVQcp1BZ2DAGlSAMlUcFMgSb8sD5A0QW4gUedIAGkiCJDWt2QHEjFrl+b0SRJA\nanU6kNRTpI3u9QEsGYI0Cqbp8YCUAiRt8LQg5bqC7kGANBj6hnoAACAASURBVCnfIKUASR8E\nSOtbbgGksgbJLhsgGeIAKZwlO5AKKkgN7ABSr6AgFUJsdIq00b0+gOVGQGK3xeMFKdcVnBFk\n1607BylP2W1xgOTSQItqtm65DZD4bXGA5NJAi2q2bskNpIIKAiRz8FQgjU+RNrrXB7AESIGz\nAZJdNVu33AJIKUAyB08JUq4tOCPIrlv3DVLOcItHA1IhxACSPgiQAmfvCCRiZLfRvT6AJTOQ\nCiKYAqSJIEBa3xIgBc7eGUjqzSzb3OsDWAKkwNm7AalZ7giQNEGAFDh7LyClzQJ8gKQJ8gKp\nIIIVR/y2eCwgSRwdSQJImiBACpy9L5BG9/tvc68PYAmQAmcDJJtqtm/JHqRmNMFui8cGUkmP\n7Da61wewBEiBs/cCUknONWx0rw9gyQqkggg2owl2WzxCkJ4Jjja61wewBEiBswGSTTXbt+QO\nUjssZ7fFIwFJeMQgQDIGAVLgbIBkUc0OLDmBVBBBgGQRBEjrWzIHqZtwZbfFowRpzNFG9/oA\nlgApcDZAsqhmB5YAKXD2XkBKS4BkCjICqRgH+0uA7LZ4HCCJBySAZAwCpMDZOwKJ4Gije30A\nS+4g5bbZzkGANF0vQLIuCJACZwOk6Wr2YMkapGGVJLstHh9IOfHjo1vd6wNY8gGpGAcBEi+Q\nMNmgDwKkwNlbBknliNkPYrOy5AyScP8Luy0OkFwaaK5mF5YAKXA2QJqsZheWwUB6dlQxDqXP\nz7mrTZTSgrTQV+iTBqSFfnsWmyNSMQ7iiMToiFRi1s4YZAyS+GBPdls8QpDY9QErS94g5URB\ne0tzECBN1guQ7AtyAakYBwHSyiAJfQKQpoJ8QZIe2c5ui0cGUvWlxq4PWFkCpMDZAGmqmn1Y\nAqTA2QBpqpp9WLIFSf4xHnZbPDqQGP4gNitLJiAVoyBAsq8GIK1vCZACZ28XJGXSjl8fsLIE\nSIGzAdJENTux5AqS8gva7LZ4XCDVl/TY9QErSx4gFaMgQHKoBiCtb8kZpHxc0N5yMgiQJupV\n5hr49QErS6YgKQckflscIBks2e/1ASwBUuDszYKkzjXw6wNWlgApcDZAMlezF0sWIBWjIEBy\nqQYgrW/JEySVI35bPCqQmhta2PUBK0uAFDgbIJmr2YslQAqcvQ+Qcuu2OAV3ZMkBpEIN1hwB\nJOtqANL6lgApcPZWQRrNNfDrA1aWfEHKxwXtLS2CAMlYL0ByK8gRpPEBid8WB0gGS/Z7fQBL\nBiAVahAgOVYTGKT2cU7s+oCVJT+Q0hQgOVYTHKTcvi1OwR1ZsgMpTVuSAJJ1NQBpfUtuIKVp\nS1I+LmhvaRMESKZ6x6dI/PqAlSVACpwNkEzV7MdyfZCIkR1AcqsGIK1vyQ2k/hwJINlXA5DW\nt2QHUknNNfDb4hGB1A0P2PUBK0uGINUl83FBMnt+ECCZ6h1P2vHrA1aWq4OkcgSQ3KvxDlJR\nACTHggApcPYWQSoKkSSAZFOQHUhpCZBcq/EMUlFIJAEkm4IAKXA2QDIEd2TJFCT1B7TZbXGA\n5NJAXXBHlmuDND5FAkjO1QQ+R8pd2uIU3JElQAqcvUWQSmqugV8fsLI0g/Tr5iyp4he/KC+T\n5oKUlgDJuRr/IAkxgLQcpKukUvW35I4yMwggmQoCpN1ZmkC6SM7uyhqkuyR5odz0sgSJGNlV\nJVWO+G1xgOQjuCNLA0h3yVkVruM3yQfKTS+AZCoIkHZnaQDpoh7PNSA9JeeUm14zQUpLgORe\nTViQcn25re71ASwNIDUINf/t/rGWFUjSkq5aAGlONQBpfcs1QZIvV9QCSHOqCQlSP7Lj1wes\nLA0gZQJIL0lGuellAZJyAb0WQJpTjfcLskIMIC0G6Uo4R/qSXFFuei0CacQRvy0OkHwEd2Rp\nAOlXkr2U/fT3A+Wm1zyQ0qYkQHKrBiCtb2m6jnSTZPV1pF83SXJDmRk07xwJIM2qBiCtb2lc\n2fAh6TTi6DFTT5q+S4F5s3YAaVY1QUHK9eUWB3dkaV5r9/Lh/EjR+c14qd2lCtLPbAZIahAg\nzaoGIK1vOXP1932mgKQGZoHUPPT7ecwRvy0eC0jDyI5fH7CyNIB0c/NEOVR6zeQj0u9rJQCQ\njAV5g1SUAMm5oPGCrBak20w+R8qyryVAAkiuwR1ZTq5soPSY3crcfPpdAiSA5BzckaVpaJd8\noxzKaqbhtRzN2g2B/1V6nlahBtLqP3meW+RCgrQgzbMT+yVFZ9jJNNlwlXwg74y9z+7VA1A5\n54hUKMHmUcWVRkXZfXVFc0TK9eWWB3dkaRzaSerjr9llGQykPCdJYrfFAZKP4I4sZ4B0mz2W\nAGlRwc2AJJwi8esDVpYzriNlvZQw7atvDUDyVA1AWt+SEUjtbzDjHMm5Gr8gFSVAci84+7l2\ny4d2hRJsQCopjvhtcYDkI7gjS3Yg5aw2z/LsjYOU68t5CO7I0uIBkeSi1Y6bAR+ABJBcgzuy\nNIJ000/Zje+PDQRSzmvzLM8GSIbgjizNN/Y1V2R/faBIMssdpO6AxGrzLM/eNEjiKRK/PmBl\naXxAZNatWn3KQtxqToCUkyUZbnGA5CO4I0vjw0++9K8DPPykUIIAaXY1XkEqhBhAsi5oXNkw\nPO87wOO4KJC0P0PPbotHAlKuL+cjuCNL29so/D8gUgGpPyCx2jzLswGSIbgjS+sj0ilA0v/E\nIrstDpB8BHdkyeYcCSABpC1bWs/aOf7S2ByQDD8fwm6LAyQfwR1Zmm/sC3gdqZCDwwGJ1eZZ\nnr1lkKRJO359wMrSuLLhyrCyYUIAyVSQMUiFEJMOSPz6gJXl1Fo73QMipzQDJNOjcdltcYDk\nI7gjy9mrvycEkEwFAdLuLPmAZHzsE7stDpB8BHdkaQTp5ab6OeYyu3KcsiudQRIOSKw2z/Js\ngGQI7sjSBNJd0v36petPMU+DVMjBqTsx2W1xgOQjuCNLA0hPSXLVrG24O3cmCSCZCm4DJHn2\nm18fsLI0Pml1+FWkc2GVg5VcQZpYZcxui+8VpEKIyQckfn3AytIAUiastXtKzig3vdxAmlyu\nz26LAyQfwR1ZrrX6WwFp6go6uy0OkHwEd2QJkAJnAyRDcEeWxtXfw6z3XXJBuek1AVIhBydP\natltcYDkI7gjS7vV3+WZ59XfAMlnNQBpfUvTdaSLJPtSofT0JfM9/S2DNN1h7LZ4BCApHPHr\nA1aWxpUNF/3qb8eBHUAyF2QLUiHEAJJLwZVWfwMkn9UApPUt11m0WkjBPNWXNMQAUieAtL4l\nC5AMJQ0xgNQJIK1vyQAk5YDEavMszwZIhuCOLLUg3V0k3b/Jue7nzfUCSKaCAGl3ljqQLtpb\nKNofpPB8G4XYX3kJkBZWEwQklSN+fcDKUgPSTZLVV2DvkuTmpfx17vkpQgDJazUAaX1LGqSn\nblHDWfvM7yx5Kp1kBKkQgiOOWG2e5dmbAknsGIDkVJAG6UPyof73JWnvSfoi3JtkJYBkKgiQ\ndmdJg3SRNJdgjyO7Zo3dL9ezJFuQ8hIgLa4GIK1vSYPU3TTxoX+QvtfbKAASQNqbpRmki/5n\nkYKAlOcER6w2z/LszYKkcsSvD1hZmkEaVquGACmvBJCWVxMCpNEBiV8fsLKkQTprRnS/ku6Z\nJ798PrNB5ChXL8fy2jzLswGSIbgjSxqkq+a3l4+nSO26b6+/jwSQmIJUCDGA5FaQBqm9s/ys\nP0Xy+vtIAAkg7c5Ss7LhrLpudNOP7G5cR3Y2IJU0R6w2z/JsgGQI7shSA9JTJiyxuzvvh3jW\nsgGpJOcaWG2e5dlbBWnEEb8+YGWpW7T6cpMlZ83x6AhU9kB5mWQFEnUVidfmWZ4NkAzBHVla\n3I+UnDs+rlj2HVU8dBdA8lMNQFrfcoUb+ySQxhyx2jzLszcK0vgUiV8fsLJcFaT8GSD5qMYT\nSMI3HEByLTgNkuuaBtV3VDFAAkj7swRIgbMBkiG4I0uAFDh7oyCNOeLXB6wsTw+SONfwTHDE\navMszwZIhuCOLIOB9KxTMbw8gqQtBtlLC5KbjdAzx66BnIQjUuDsTR6RUuIUiV8fsLJcF6QU\nIPmoxg9IIkep5RrIje71ASxPfx1J6K8jSJhs8FCNZ5DSGiSrVfkb3esDWK4IUt1bBEmcNs/y\n7E2CVK3KB0hOBW1B8naruTQQB0heqvENkv19Yhvd6wNYam41/6DmASSfBXmD1N5xOa8tTsEd\nWeoefqLeOBEApJLmiNXmWZ69SZBSgORaUAdSksgHpVAgWTRRFwNInQDS+pY6kH6dJedPUoRy\n08sOJPabZ3n2ZkCSOobgiF8fsLLUP9fuKsm+yREXASRTQeYgVdMNc9viFNyRpeEBkd8y4Rlc\nvkASuwsgeaomAEiz2+IU3JGl6UmrT+fJ2S8pYi+AZCrIHKSUuNGcYR+wspx8iP4XOWIrgGQq\nyB2kfBN9wMrSDFL5kCUXL1LEUgDJVBAg7c5yAqT6BykeSoDktyBA2p3lJEjll/pX+zyBJHJ0\nHIiz3zzLswGSIbgjy2mQyqfqkhJA8lmQIUjyXMMm+oCVpQVI9UPAAZLPggBpd5ZWIJV3GUDy\nWRAg7c7S8jaKlw9+fmhMnmvgv3mWZwMkQ3BHlie+sQ8guZVcA6S0BEjuBU8LkjKy4795lmcD\nJENwR5YAKXD2FkGiT17Z9QErS4AUOHsjICkr7TbRB6wsAVLgbIBkCO7IEiAFzt4cSKnuugS7\nPmBlCZACZwMkQ3BHlicFSeIIIHmrBiCtb7keSClA8lUNQFrfEiAFzgZIhuCOLAFS4OxtgCRx\nBJBmFKRBypKxKDe9pkHKbZuoiwGkTgBpfUsapAuA5CsbIBmCO7KkQfqSnH1QnlnsKAqk0aQd\n/82zPHuDIGnG3Oz6gJUlDdLTVTW4u/r2QllYCSCZCgKk3VlqJxsebiqWzj/8KmdpEqQUIHmr\nxiNIzchuG33AytI0a/f04ezIUnZ1RxlNCCCZCgKk3VlOTH8/fTmvJhrOvzxRfzUIIJkKcgNJ\nnWvYRh+wspy+jvTyrZ7DyzR/1gggmQoCpN1ZWl2QfbnxMf0tzzUAJH/VAKT1LW2OSFfVEWn5\nw08AknvJU4NU//AbQJpRcOoc6Vt9jnTxzcM5EkByLwmQtmJpMWt342nWTj5FwnUkf9UApPUt\np64jOU/XjXz7igGSe8k1QNJ1DLs+YGVpWNmQXd15XdkwnrTjv3mWZ28BpNFcwzb6gJXl6dba\nEadI/DfP8uxNgdSN7LbRB6wsT7f6GyDNKAmQtmJ5uvuRANKMkgBpK5anu0OWmGvgv3mWZwMk\nQ3BHlgApcDZAMgR3ZHkqkIoCIM0oeVqQao4A0qyCJwKpKGSSAJLPagDS+pa2IKmTDY+ZtBz8\n8TrLrn+SvpWKQiEJIPmsZiFI8sgOIM0qOBekSwmkI1aVvlO+lQDSzJIAaSuWM0G6zySQLrP/\nyvI/MQSQTAV5gjRwtI0+YGU5D6TXTDoiPTbHoq8VTiPfWiOOAJLHagDS+pbzQLrNpHOkr9nv\n6p/f2SfCtxE518B/8yzPBkiG4I4sZ4H0mN2WIkjXzevjcYrwpSoGSF6rAUjrW84C6TJ7lUDq\nXgsxgGQqCJB2ZzkHpPvsvjSB9L9Kzyalz7nx75CTtCDZJB8H3c2LtPkHPTNLM0BqRnA4Ii0o\nyOiINEwDNQckHJHmFZwB0m32WAKkRQX5gCRcmABISyxngJT16iK3HUjXhC9RcTf7zX/zLM8G\nSIbgjixpkIjbkUwgWUx/A6RZJQHSVixngNSIuCD7PRtW2wEkU0E+IJUkR9voA1aWs1d/U0uE\nDpQvUTFA4gNSSc01bKMPWFkuBan553cz1BtWCAEkY0FWILVRgLTI0g9IU7dRKBUDJIC0N8vT\n3WouvAZIfEAquihAWmSpB+nuQx1t5PzUYhNIPUf8N8/y7K2A1HIEkGYW1IH0dJ4k1dOKW5Ac\nfx0JIJkLAqTdWWpAesqS7FsdrcMXyQ1lZhBAMhXkA1LRRQHSMksNSBfJeRutw7+cD0kAyVQQ\nIO3OkgZpAKe9EHvuepYEkEwFAdLuLGmQbpIPXbQJf0uuKDe9AJKpIBuQii4qc7SNPmBlSYN0\nnvzqok34VzfUs5UBpO6nQ2yb6FQQIBniACmcpW6tnfrKw48xdwJIAGl/llMg6SNmASRTQYC0\nO0uAFDibNUhFHwVICy1pkM4S5Ucvn5Izyk0vgGQqyA6kjiOANLcgDdJFovzw5Z3HWTuABJD2\nZ0mD9E1dyXDl8TrSMPvNf/Msz+YMUtFHAdJSSxqkl0Qe2z15XNkgHJD4b57l2QDJENyRpWaJ\n0I183eg8+UKZGQSQTAUB0u4sdau/z5Pz/pj0cu56ORYgmQtyA6nnCCDNLWi6jeLmoWLp4SZz\n5wggGQvyAKnoo+oBaRt9wMpSf2Pfh+EBQh9KZwEkU0GAtDtL063m3y6yJMkuvr2M/jItgGQq\nCJB2Z3n6ZzYAJIeSIUEq+ujoFGkbfcDK8uQg1Z0GkLxWA5DWtwRIgbMBUhyWAClwNluQiiEK\nkJZbAqTA2QApDkuAFDh7AyANHAGkbYGUq0Gy5FQMIHUCSOtbAqTA2VxBKoboeGS3jT5gZXlq\nkKSRHf/NszwbIMVhCZACZ7MHKU0BkgdLgBQ4mylIIkfpaIXQNvqAlSVACpzNHKQ0FUkCSADp\nxJYAyUdwR5YAKXA2QIrDEiAFzuYJ0jBnh3MkP5YnBqnpMoDEByTM2vmxBEiBs9mDVBILG7bR\nB6wsAVLgbJYgSRwJdgBpUyDlSpAsOR0DSJ18gWTuGHZ9wMoSIAXOBkhxWAKkwNkAKQ7L04Kk\nnCLx3zzLszmCJHIEkPxYAqTA2QApDkuAFDgbIMVhCZACZzMESeIIIPmxBEiBs7mDlAp2AAkg\nndoSIPkI7sgSIAXO5geSMrIDSF4sTwpSu6oLIPEEKVdLzmmLU3BHlgApcDZAisMyGEjPhNLm\nn5z6GzRfWpDI0oX0Lh1eol8WaIUj0sQXH6vvmeXZ7I5I8gEJRyRPlgApcDZAisMSIAXOBkhx\nWAKkwNncQBpxBJC8WJ4SpNGkHf/NszwbIMVhCZACZwOkOCwBUuBsgBSHJUAKnM0MJIUjgOTL\nEiAFzt4OSLlccmZbnII7sgRIgbMBUhyWAClwNi+QVI4Aki/LE4I0elL7BjbP8myAFIclQAqc\nzRukVLADSEssTw/SVH+x2jzLs1mBRB2QAJIXS4AUOBsgxWEJkAJnMwKpKABSMEuAFDibD0hF\nMSYJIPmyPB1IxFwD/82zPJsNSEVBkASQfFkCpMDZmwFJ7Jdt9AErS4AUOBsgxWEJkAJnswGJ\nOkdKBTuAtMgSIAXO5gMSMWsHkLxZAqTA2YxAGicCJG+WAClwNkCKw/JUIKUpQJpREiBtxfJE\nIKVpR9Jkf7HaPMuzAVIclqcBKU17kgCSS0mAtBVLgBQ4GyDFYQmQAmcDpDgscY4UOJszSKkQ\nzY0l7dviFNyR5cln7QCSS0mAtBXLkz77uxJAcikJkLZiCZACZwOkOCwBUuBsgBSHJUAKnA2Q\n4rAESIGzAVIclgApcDZAisMSIAXOBkhxWJ4apOn+YrV5lmczBikVowBpmSVACpy9EZByY0mH\ntjgFd2QJkAJnA6Q4LAFS4GyAFIclQAqcDZDisARIgbMBUhyWAClwNkCKwxIgBc4GSHFYAqTA\n2XxBSsUoQFpoCZACZwOkOCwBUuBsgBSHJUAKnL0NkHJjSZe2OAV3ZHlikCy++FhtnuXZACkO\nS4AUOBsgxWE5C6Tvl9nh66sYub/Msk9/SF+pYoDkVhIgbcVyDkjXWaWDwM3XOpI9Ur5SxQDJ\nrSRA2orlDJDus+s/5eun7LaP/MwOR4b+XB8oX6ligORWEiBtxXIGSJdZParLsj5y3RyLHrP/\nCF+pYoDkVjIgSKkYBUhLLedPNmTD8adjSjhIASRTQYC0O8u5IP25Fg4/PUgDWwDJVBAg7c5y\nJkhZlv0c3l1mv6t/fgqjPYBkKgiQdmc5D6Tf17fZYSCpnn4ofx5akP5X6ZlUToehRdKCZEpK\nxTfol6WafY70ei3MdjcT4l9xRLIsyO2IpB6QttEHrCznTzb8zq6HN/eH7PK/EiBZFgRIu7Nc\nsERIwKbRb8zaWRYESLuz9AnSffaV8BUrtjmnZbV5lmcDpDgsZ4B0aC7I/sw+KZFPwlkTQDIV\nZABSKkYB0mLLGSB9z66P3DwemjnvSl+ryOu9eNIEkEwFAdLuLOcvWs2+V6/r8d3rYbSMFSCZ\nCgKk3VnOOkeqbpq4bYZxzYnS69dDdvlVLAKQTAUB0u4sT3tjH0ByLAmQtmIJkAJnA6Q4LAFS\n4OwtgDTiaBt9wMoSIAXOBkhxWAKkwNlMQUrFKEBabgmQAmcDpDgsAVLgbIAUh+VJQbKaHGK1\neZZnA6Q4LAFS4GyAFIclQAqcDZDisARIgbMBUhyWAClwNkCKwxIgBc4GSHFYAqTA2TxBSsXo\nmKNt9AErS4AUOBsgxWEJkAJnA6Q4LAFS4GyAFIclQAqcDZDisARIgbMBUhyWAClwNkCKw/KU\nINldrmC1eZZnA6Q4LAFS4GyWIKVSFCB5sARIgbMBUhyWAClwNn+QCI620QesLAFS4GyAFIcl\nQAqczR6kPMfQzoMlQAqczR2kPKdI2kQfsLIESIGzmYOU5yRJm+gDVpYAKXA2QIrDEiAFzgZI\ncVgCpMDZHEFS5hpwjuTBEiAFzuYOEmbt/FieECTL/mK1eZZn8wfJb1ucgjuyBEiBswFSHJYA\nKXA2d5Byz21xCu7IEiAFzgZIcVgCpMDZACkOS4AUOBsgxWEJkAJnMwcp990Wp+COLAFS4GyG\nIMkHJIDkxRIgBc4GSHFYAqTA2QApDkuAFDibN0i597Y4BXdkCZACZwOkOCwBUuBsgBSH5elA\nsn3GBqvNszwbIMVhCZACZ7MGKfffFqfgjiwBUuBsfiApBySA5MUSIAXOBkhxWAKkwNmcQcoD\ntMUpuCPLYCA9q8pHEciTtCCRpdP+FbrEn3BECpyNI1IclgApcDZAisMSIAXOZgxSHqItTsEd\nWQKkwNkAKQ5LgBQ4GyDFYQmQAmezA0k9RQJIXixPBhLFEf/NszybL0i5GPXWFqfgjiwBUuBs\ngBSHJUAKnA2Q4rA8FUjko9r5b57l2QApDssTgUT/eAj/zbM8my1IuRT11han4I4sTwOS5ues\n+G+e5dkAKQ5LgBQ4GyDFYQmQAmcDpDgscY4UOJsbSCOOAJIXS8zaBc4GSHFYnvBxXBat0QbZ\nbXGA5CO4I0uAFDgbIMVhCZACZzMFKZej/triFNyRJUAKnA2Q4rAESIGzAVIclgApcDZPkHIl\n6q8tTsEdWQKkwNnMQBofkACSF0uAFDgbIMVhCZACZwOkOCwBUuBsliDlStRjW5yCO7IESIGz\nAVIclgApcDZAisMSIAXOBkhxWAKkwNkcQcrVqMe2OAV3ZAmQAmcDpDgsAVLgbF4gESM7gOTF\nEiAFzgZIcVgCpMDZDEHK1ajPtjgFd2QJkAJnA6Q4LAFS4GyAFIclQAqcDZDisARIgbP5gaQ+\nzgkg+bAESIGzAVIclgApcDZAisMSIAXOZgUSxRFA8mIJkAJnA6Q4LAFS4GyAFIclQAqcDZDi\nsARIgbO5gWT32zqb6ANWlgApcDZAisMSIAXOBkhxWAKkwNkAKQ5LgBQ4mxNIJEcAyYslQAqc\nzQikNE0BUihLgBQ4mw9IaSWAFMgSIAXOZgNSCpBCWgKkwNm8QMrTcSmA5MNyFkjfL7PD11cx\n8vs2yz79IX1dWqMNstviAMlHcEeWc0C6ziodBG5+15FMiAAkU8E1QCo1IzuA5MVyBkj32fWf\n8vVTdjuEbrP7Ki5EAJKp4CoglQApoOUMkC6zelSXZUOoeS1GAJKp4Doglc8URwDJi+X8yYbs\nMLw+ZGoEIJkKAqTdWc4F6c919t/w7nsztPtO+bq0Rhtkt8W3CFKeA6RgljNByrLsp/j+++EY\n6Tj6X6Vn6GTSgiSVyiut1ML9ax5Iv69vs8NP8X01aXeLWTvLgmsckfJGodviFNyR5exzpNfr\n7LF7/buaxzvSJMyIAyRTQYC0O8v5kw1HerqXnxqmHrNPhK9La7RBdlscIPkI7shywRKhYba7\neyXMfwMkU8E1QCo1HAEkL5YAKXA2H5AwaxfScgZIh+aC7M9hIHfdRB6HwR5AMhZcB6STtMUp\nuCPLGSB9z66P3Dwest9d5Gd2/VhfWhom8gCSqSBA2p3l/EWrzWWjZjT3tYl8pXxdWqMNstvi\nAMlHcEeWs86R7i+z7LaZ/G5Pi34e4boWL9ECJFNBgLQ7S9zYFzgbIMVhCZACZwOkOCwBUuBs\ngBSHJUAKnA2Q4rAESIGzAVIclgApcDZAisMSIAXOBkhxWAKkwNkAKQ5LgBQ4GyDFYQmQAmcD\npDgsAVLgbIAUhyVACpwNkOKwBEiBswFSHJYAKXA2QIrDEiAFzgZIcVgCpMDZACkOS4AUOBsg\nxWEJkAJnA6Q4LAFS4GyAFIclQAqcDZDisARIgbMBUhyWwUCCTih0wvoKBNK4UyO15NRITm3Z\nryVACmLJqZGc2rJfS4AUxJJTIzm1Zb+WACmIJadGcmrLfi0DgwRBcQggQZAHASQI8iCABEEe\nBJAgyIO8gfQ90//tUf4dpcfMUHaG5ffL7PD11avl/fH15b1Px4miDoVEV7mGWPuAQyf4Aumn\noWMehd/6q3Rp14m2ls1PCR7+eLcUfhx3seNEUSu/satcQ6x9wKITPIF0nxnqvsz+K8v/+gLG\nsu6W99n1n/L1U3brz/JrZVn9Xu53bWlHx6miVn5jV6mGWPuARyd4Aen3dWb4hntstsXXqr6j\nXk1lZ1heNj+uPu1pb3loSv3ODr4cJ4pO+/Vh0VV8HWsfcOkELyBVP8g8VKL+sOzX5ofQf2ef\n6re3mc343MmyTpja4O6WkzuGg6NUdIZfHxZdxdexRFMv7wAAA3lJREFU9gGXTvAC0qffQyX/\njX7q/Lr5y/FbsG7a8fhv0Ykulkf9uW6/a/1ZHiW+XugoFp3j1+eKruLrWPuASyd4m7XLukPx\n9WN9ePyp/qXsRpSvNp3oYln9m/1UsxdaltU55/T43MXR6mNr/EYm1b/jzWDXlr31AYdO8A3S\n12a0/Cqcd0qf5T67t/ww1pbVR73NDla9aG1Z6XJypOLm6NKHol/WqyT7UP03uj7g0Am+QboU\n65ObXv3bHGLdOnHCstHrdfbo2fI2s5nNdXB06UPRzxWk6PqAQyf4Bkmob2jCUOK23tRunThh\n2eq31RUHB8uvdiMVB0eXPpT6jTIxgBRdH3DoBP8gCZGmCbddrdfjpnmwVEr7snTuw+lGzmyh\n/F50VWuItQ84dIJvkA7NZKAoeZLWvRMnLJXSfixfrw82oxS3Ri5pofAlTU9/27dlf33AoRN8\ng/SpabF4kG+vWH3PxvPxPiwPzRnhT7FDl7byz8FqtYuDo1B0ll+fK7qqNcTaBxw6wf/0dzXr\n/vsgHpTb9RQHtawfy+/Z9Wu9lmT0bTTb8vVgNVfk4CgWne03dlVqiLUPOHSCb5CqBX+VhGti\nVXsq/Tcq68eyXd1oc73B0vKTw+DH4XO79CHlN3ZVaoi1Dzh0gneQyj9fD+rqd3XhhmMnTlne\nX2bZrd1w2s7S5SzC4XM79SHlN3bVLGGJrA84dAJu7IMgDwJIEORBAAmCPAggQZAHASQI8iCA\nBEEeBJAgyIMAEgR5EECCIA8CSBDkQQAJgjwIIEGQBwEkCPIggARBHgSQIMiDABIEeRBAgiAP\nAkgbV5KUT1dZkl39WrslcQsgbVxJcpc0ulm7KVELIG1cR4LOH47/fsmSD2u3JWYBpI0rSdoH\ndTwlycu6TYlaAGnjSpJv7asPOCStKIC0cSXJU/vqKTlftSVxCyBtXElCvYROLWz7jQsg8RC2\n/cYFkHgI237jGubqfiUXq7YkbgGkjStJ7tpXH/r5O+j0AkgbV9LN1T0lGa4jrSeAtHElSXLx\nUJYvX4ZDE7SCANLGlSQPZ81aO3C0pgDSxlVN1d1kydkHjOtWFUDauDDnzUPoho0LIPEQumHj\nAkg8hG7YuAASD6EbNi6AxEPoho0LIPEQugGCPAggQZAHASQI8iCABEEeBJAgyIMAEgR5EECC\nIA8CSBDkQf8HR/WYgHukAacAAAAASUVORK5CYII=",
      "text/plain": [
       "plot without title"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 420,
       "width": 420
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "ggplot(params, aes(x = p, y = score, color = as.factor(h2))) +\n",
    "  theme_bigstatsr() +\n",
    "  geom_point() +\n",
    "  geom_line() +\n",
    "  scale_x_log10(breaks = 10^(-5:0), minor_breaks = params$p) +\n",
    "  facet_wrap(~ sparse, labeller = label_both) +\n",
    "  labs(y = \"GLM Z-Score\", color = \"h2\") +\n",
    "  theme(legend.position = \"top\", panel.spacing = unit(1, \"lines\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "twelve-shuttle",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Attaching package: 'dplyr'\n",
      "\n",
      "\n",
      "The following objects are masked from 'package:stats':\n",
      "\n",
      "    filter, lag\n",
      "\n",
      "\n",
      "The following objects are masked from 'package:base':\n",
      "\n",
      "    intersect, setdiff, setequal, union\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "library(dplyr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "lined-virgin",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"dataframe\">\n",
       "<caption>A data.frame: 10 × 6</caption>\n",
       "<thead>\n",
       "\t<tr><th scope=col>p</th><th scope=col>h2</th><th scope=col>sparse</th><th scope=col>score</th><th scope=col>sparsity</th><th scope=col>id</th></tr>\n",
       "\t<tr><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;lgl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;int&gt;</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><td>0.0056</td><td>0.0683</td><td> TRUE</td><td>4.293</td><td>0.589</td><td>59</td></tr>\n",
       "\t<tr><td>0.0320</td><td>0.1366</td><td>FALSE</td><td>4.286</td><td>0.000</td><td>45</td></tr>\n",
       "\t<tr><td>0.0032</td><td>0.0976</td><td> TRUE</td><td>4.285</td><td>0.574</td><td>75</td></tr>\n",
       "\t<tr><td>0.0056</td><td>0.0976</td><td> TRUE</td><td>4.284</td><td>0.572</td><td>76</td></tr>\n",
       "\t<tr><td>0.0100</td><td>0.0976</td><td> TRUE</td><td>4.282</td><td>0.573</td><td>77</td></tr>\n",
       "\t<tr><td>0.0560</td><td>0.1366</td><td>FALSE</td><td>4.282</td><td>0.000</td><td>46</td></tr>\n",
       "\t<tr><td>0.0560</td><td>0.1366</td><td> TRUE</td><td>4.280</td><td>0.560</td><td>97</td></tr>\n",
       "\t<tr><td>0.0018</td><td>0.1366</td><td>FALSE</td><td>4.279</td><td>0.000</td><td>40</td></tr>\n",
       "\t<tr><td>0.3200</td><td>0.0976</td><td> TRUE</td><td>4.278</td><td>0.584</td><td>83</td></tr>\n",
       "\t<tr><td>0.0320</td><td>0.0683</td><td> TRUE</td><td>4.278</td><td>0.592</td><td>62</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A data.frame: 10 × 6\n",
       "\\begin{tabular}{llllll}\n",
       " p & h2 & sparse & score & sparsity & id\\\\\n",
       " <dbl> & <dbl> & <lgl> & <dbl> & <dbl> & <int>\\\\\n",
       "\\hline\n",
       "\t 0.0056 & 0.0683 &  TRUE & 4.293 & 0.589 & 59\\\\\n",
       "\t 0.0320 & 0.1366 & FALSE & 4.286 & 0.000 & 45\\\\\n",
       "\t 0.0032 & 0.0976 &  TRUE & 4.285 & 0.574 & 75\\\\\n",
       "\t 0.0056 & 0.0976 &  TRUE & 4.284 & 0.572 & 76\\\\\n",
       "\t 0.0100 & 0.0976 &  TRUE & 4.282 & 0.573 & 77\\\\\n",
       "\t 0.0560 & 0.1366 & FALSE & 4.282 & 0.000 & 46\\\\\n",
       "\t 0.0560 & 0.1366 &  TRUE & 4.280 & 0.560 & 97\\\\\n",
       "\t 0.0018 & 0.1366 & FALSE & 4.279 & 0.000 & 40\\\\\n",
       "\t 0.3200 & 0.0976 &  TRUE & 4.278 & 0.584 & 83\\\\\n",
       "\t 0.0320 & 0.0683 &  TRUE & 4.278 & 0.592 & 62\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A data.frame: 10 × 6\n",
       "\n",
       "| p &lt;dbl&gt; | h2 &lt;dbl&gt; | sparse &lt;lgl&gt; | score &lt;dbl&gt; | sparsity &lt;dbl&gt; | id &lt;int&gt; |\n",
       "|---|---|---|---|---|---|\n",
       "| 0.0056 | 0.0683 |  TRUE | 4.293 | 0.589 | 59 |\n",
       "| 0.0320 | 0.1366 | FALSE | 4.286 | 0.000 | 45 |\n",
       "| 0.0032 | 0.0976 |  TRUE | 4.285 | 0.574 | 75 |\n",
       "| 0.0056 | 0.0976 |  TRUE | 4.284 | 0.572 | 76 |\n",
       "| 0.0100 | 0.0976 |  TRUE | 4.282 | 0.573 | 77 |\n",
       "| 0.0560 | 0.1366 | FALSE | 4.282 | 0.000 | 46 |\n",
       "| 0.0560 | 0.1366 |  TRUE | 4.280 | 0.560 | 97 |\n",
       "| 0.0018 | 0.1366 | FALSE | 4.279 | 0.000 | 40 |\n",
       "| 0.3200 | 0.0976 |  TRUE | 4.278 | 0.584 | 83 |\n",
       "| 0.0320 | 0.0683 |  TRUE | 4.278 | 0.592 | 62 |\n",
       "\n"
      ],
      "text/plain": [
       "   p      h2     sparse score sparsity id\n",
       "1  0.0056 0.0683  TRUE  4.293 0.589    59\n",
       "2  0.0320 0.1366 FALSE  4.286 0.000    45\n",
       "3  0.0032 0.0976  TRUE  4.285 0.574    75\n",
       "4  0.0056 0.0976  TRUE  4.284 0.572    76\n",
       "5  0.0100 0.0976  TRUE  4.282 0.573    77\n",
       "6  0.0560 0.1366 FALSE  4.282 0.000    46\n",
       "7  0.0560 0.1366  TRUE  4.280 0.560    97\n",
       "8  0.0018 0.1366 FALSE  4.279 0.000    40\n",
       "9  0.3200 0.0976  TRUE  4.278 0.584    83\n",
       "10 0.0320 0.0683  TRUE  4.278 0.592    62"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "params %>%\n",
    "  mutate(sparsity = colMeans(beta_grid == 0), id = row_number()) %>%\n",
    "  arrange(desc(score)) %>%\n",
    "  mutate_at(c(\"score\", \"sparsity\"), round, digits = 3) %>%\n",
    "  slice(1:10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unavailable-behalf",
   "metadata": {},
   "source": [
    "You can then choose the best model according to your preferred criterion (e.g. max AUC). Here, we use the Z-Score from the regression of the phenotype by the PRS since we have found it more robust than using the AUC. It also enables adjusting for covariates in this step (using parameter covar.train in big_univLogReg() or big_univLinReg()).\n",
    "\n",
    "Also note that we separate both sparse and non-sparse models here (and in the paper) to show that their predictive performance are similar. In practice, if you do not really care about sparsity, you could choose the best LDpred2-grid model among all sparse and non-sparse models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "extraordinary-project",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       ".dl-inline {width: auto; margin:0; padding: 0}\n",
       ".dl-inline>dt, .dl-inline>dd {float: none; width: auto; display: inline-block}\n",
       ".dl-inline>dt::after {content: \":\\0020\"; padding-right: .5ex}\n",
       ".dl-inline>dt:not(:first-of-type) {padding-left: .5ex}\n",
       "</style><dl class=dl-inline><dt>Mean</dt><dd>0.668297949296717</dd><dt>2.5%</dt><dd>0.573912081569835</dd><dt>97.5%</dt><dd>0.759858612142243</dd><dt>Sd</dt><dd>0.0473452871736604</dd></dl>\n"
      ],
      "text/latex": [
       "\\begin{description*}\n",
       "\\item[Mean] 0.668297949296717\n",
       "\\item[2.5\\textbackslash{}\\%] 0.573912081569835\n",
       "\\item[97.5\\textbackslash{}\\%] 0.759858612142243\n",
       "\\item[Sd] 0.0473452871736604\n",
       "\\end{description*}\n"
      ],
      "text/markdown": [
       "Mean\n",
       ":   0.6682979492967172.5%\n",
       ":   0.57391208156983597.5%\n",
       ":   0.759858612142243Sd\n",
       ":   0.0473452871736604\n",
       "\n"
      ],
      "text/plain": [
       "      Mean       2.5%      97.5%         Sd \n",
       "0.66829795 0.57391208 0.75985861 0.04734529 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "best_grid_nosp <- params %>%\n",
    "  mutate(id = row_number()) %>%\n",
    "  filter(!sparse) %>% \n",
    "  arrange(desc(score)) %>%\n",
    "  slice(1) %>%\n",
    "  pull(id) %>% \n",
    "  beta_grid[, .]\n",
    "\n",
    "pred_nosp <- big_prodVec(G, best_grid_nosp, ind.row = ind.test, ind.col = ind.chr2)\n",
    "AUCBoot(pred_nosp, y[ind.test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "concrete-small",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       ".dl-inline {width: auto; margin:0; padding: 0}\n",
       ".dl-inline>dt, .dl-inline>dd {float: none; width: auto; display: inline-block}\n",
       ".dl-inline>dt::after {content: \":\\0020\"; padding-right: .5ex}\n",
       ".dl-inline>dt:not(:first-of-type) {padding-left: .5ex}\n",
       "</style><dl class=dl-inline><dt>Mean</dt><dd>0.673767770787055</dd><dt>2.5%</dt><dd>0.575607855224888</dd><dt>97.5%</dt><dd>0.767411203323192</dd><dt>Sd</dt><dd>0.048626264565106</dd></dl>\n"
      ],
      "text/latex": [
       "\\begin{description*}\n",
       "\\item[Mean] 0.673767770787055\n",
       "\\item[2.5\\textbackslash{}\\%] 0.575607855224888\n",
       "\\item[97.5\\textbackslash{}\\%] 0.767411203323192\n",
       "\\item[Sd] 0.048626264565106\n",
       "\\end{description*}\n"
      ],
      "text/markdown": [
       "Mean\n",
       ":   0.6737677707870552.5%\n",
       ":   0.57560785522488897.5%\n",
       ":   0.767411203323192Sd\n",
       ":   0.048626264565106\n",
       "\n"
      ],
      "text/plain": [
       "      Mean       2.5%      97.5%         Sd \n",
       "0.67376777 0.57560786 0.76741120 0.04862626 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "best_grid_sp <- params %>%\n",
    "  mutate(id = row_number()) %>%\n",
    "  filter(sparse) %>% \n",
    "  arrange(desc(score)) %>%\n",
    "  slice(1) %>%\n",
    "  pull(id) %>% \n",
    "  beta_grid[, .]\n",
    "\n",
    "pred_sp <- big_prodVec(G, best_grid_sp, ind.row = ind.test, ind.col = ind.chr2)\n",
    "AUCBoot(pred_sp, y[ind.test])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "productive-consensus",
   "metadata": {},
   "source": [
    "## Automatic model\n",
    "We recommend to run many of them in parallel with different initial values for p (e.g. length.out = 30)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "addressed-kentucky",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List of 4\n",
      " $ :List of 8\n",
      "  ..$ beta_est   : num [1:44947] -1.17e-06 -5.33e-06 -8.73e-06 -7.82e-06 -8.15e-07 ...\n",
      "  ..$ postp_est  : num [1:44947] 0.126 0.126 0.126 0.126 0.126 ...\n",
      "  ..$ p_est      : num 0.126\n",
      "  ..$ h2_est     : num 0.00159\n",
      "  ..$ path_p_est : num [1:1500] 0.000102 0.000141 0.000106 0.000194 0.000184 ...\n",
      "  ..$ path_h2_est: num [1:1500] 0.0155 0.0365 0.0327 0.0643 0.0901 ...\n",
      "  ..$ h2_init    : num 0.0976\n",
      "  ..$ p_init     : num 1e-04\n",
      " $ :List of 8\n",
      "  ..$ beta_est   : num [1:44947] -1.59e-07 -7.26e-07 -1.19e-06 -1.07e-06 -1.12e-07 ...\n",
      "  ..$ postp_est  : num [1:44947] 0.0118 0.0118 0.0118 0.0118 0.0118 ...\n",
      "  ..$ p_est      : num 0.0118\n",
      "  ..$ h2_est     : num 0.000218\n",
      "  ..$ path_p_est : num [1:1500] 0.00184 0.00187 0.00203 0.00187 0.00185 ...\n",
      "  ..$ path_h2_est: num [1:1500] 0.101 0.116 0.145 0.138 0.144 ...\n",
      "  ..$ h2_init    : num 0.0976\n",
      "  ..$ p_init     : num 0.00208\n",
      " $ :List of 8\n",
      "  ..$ beta_est   : num [1:44947] -1.27e-06 -5.80e-06 -9.50e-06 -8.51e-06 -8.85e-07 ...\n",
      "  ..$ postp_est  : num [1:44947] 0.0511 0.0511 0.0511 0.0511 0.0511 ...\n",
      "  ..$ p_est      : num 0.0511\n",
      "  ..$ h2_est     : num 0.00173\n",
      "  ..$ path_p_est : num [1:1500] 0.0452 0.0458 0.0451 0.0442 0.0462 ...\n",
      "  ..$ path_h2_est: num [1:1500] 0.0921 0.0914 0.0835 0.0965 0.0946 ...\n",
      "  ..$ h2_init    : num 0.0976\n",
      "  ..$ p_init     : num 0.0433\n",
      " $ :List of 8\n",
      "  ..$ beta_est   : num [1:44947] -7.67e-06 -3.50e-05 -5.74e-05 -5.14e-05 -5.23e-06 ...\n",
      "  ..$ postp_est  : num [1:44947] 0.901 0.901 0.901 0.901 0.901 ...\n",
      "  ..$ p_est      : num 0.901\n",
      "  ..$ h2_est     : num 0.0105\n",
      "  ..$ path_p_est : num [1:1500] 0.898 0.899 0.896 0.895 0.897 ...\n",
      "  ..$ path_h2_est: num [1:1500] 0.0921 0.0896 0.0913 0.0909 0.0899 ...\n",
      "  ..$ h2_init    : num 0.0976\n",
      "  ..$ p_init     : num 0.9\n"
     ]
    }
   ],
   "source": [
    "# takes a few minutes\n",
    "multi_auto <- snp_ldpred2_auto(corr, df_beta, h2_init = h2_est,\n",
    "                               vec_p_init = seq_log(1e-4, 0.9, length.out = NCORES),\n",
    "                               ncores = NCORES)\n",
    "str(multi_auto)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "interpreted-folks",
   "metadata": {},
   "source": [
    "You should verify if the chains “converged”. You can look at the path of the chains, as shown below. In the paper, we propose an automatic way to filter bad chains by comparing the scale of the resulting predictions (see this [code](https://github.com/privefl/paper-ldpred2/blob/master/code/run-ldpred2-gwide.R#L108-L112), reproduced below).\n",
    "\n",
    "This is not the case here, which is probably because the data is so small."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "anonymous-indianapolis",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA0gAAANICAMAAADKOT/pAAAAY1BMVEUAAAAAAP8zMzNNTU1o\naGh8fHyDg4OMjIyVlZWampqjo6Onp6evr6+ysrK5ubm9vb3BwcHHx8fJycnQ0NDR0dHY2NjZ\n2dne3t7h4eHk5OTp6enq6urr6+vv7+/w8PD19fX///+uVitiAAAACXBIWXMAABJ0AAASdAHe\nZh94AAAgAElEQVR4nO2dbWPiOLJGdUfbLMtmMmwm2SxDeuL//ytvg3kxIL9gl0pS6TwfGmKD\nT5XNaWPZgGsIIYvjUhdAiIW41AUQYiEudQGEWIhLXQAhFuJSF0CIhbjUBRBiIS51AYRYiEtd\nACEW4rRAvxFiLwlEGpn/pVJFGprp5qqmIZIqzXRzVdMQSZVmurmqaYikSjPdXNU0RFKlmW6u\nahoiqdJMN1c1DZFUaaabq5qGSKo0081VTUMkVZrp5qqmIZIqzXRzVdMQSZVmurmqaYikSsut\nOfcrejTRZEZDJFVaNs0dDXJt4tNiJDMaIqnS8mjOPSQmLVIyoyGSKi2H5h41EjJJqbdTuRms\nyW4QSZUWDxfUIUQLeiRikkRv46WcC87sZYJIqrRouLAQXz0PiqPS0t4mlSP8dnRqEGksNkQK\nvAKv/2sP+yMn1MzeztRpdYiqPz2INBYDIo1Y8aRH81+f83p7ro65tS71DpHGUr5II1aMSfOE\nSSMvxlm9DZd37WHsoRMhc0o8BJHGUqZIndfElFfi4Itv6itz9JUYTaQnmhkFzKlxSm+IpEoT\nwsm+6p581N2U0d6GXr2LG+mrdmjhQ2u2L4g0lvJEkn/RTXnc48SHx4R7uz6tf4kiaU7OnimD\nj3w2iDSW4kTqf3k89ZqbtsyBg6jH5U07/TuBOZaeZ09fZLDMwbWOSGMpTKSRV8e0l+CzSw4s\nJ/TK/LpbVu9ie3HTqjmtyacKDixlkH+fLEX6P0KshT2SKu153Pk/StfzLmvwP9Px/2n7n/P8\nf/GzTv+ey3uocujBh3wtKnawllAVY6sNkVRpT+POm/GprX+lTXsRBJEzX4Qzn9ZTx/XOw2Mv\n2k6CPtNZeD2MrLXZIr35/nm7jfebz76HItLUPLXdw7TxV8Az6LGKJtc8rfz7iu56Gy33YflP\nFze90Lkiffp+kXb+mLeehyLSlEzYrONbd1FzvczOhEWvTMmLdiYvP1axM0V69wMirf1H03yc\nH/DwUESaEJmX4MLmQsy7CZNfg6HHLypu9Mr2ST09k8FyZom03/h1v0i7dl+0PegUeigijWbB\nBp1BG6mjud/33ZTx7CtwVh+h3Pd2X1Pf83qLfKqNh8wSyfttc7Hj7oDoYND+cLP3r/cPvUeG\ng0jzN+cc2kglfQXe/flQZX/FMxoJZHZvl/JCM3RFet03Fzs+2gOi7XXupp3z7dd3D31AhlO1\nSGMb04nSpBIssr9aCY/i9NazyicUPHvU7mTH3m92xzdwn/dzrv5cRWp/JPCL9GXUo9QF9qeI\nIkfTs8LHm1oq0tZ/H26+/csUkVqbRpZc8R4puP+ZsyuaRBPO3Q4pdhQ+a+yeoC0Vae3PuZ+D\nSE/jgh5Fo4nnS6jqibRIy21buG8jukj+KtLZJ0SaiRP3SH1VKnoU9fuYZtCWi9SZ0or0chZp\nc/vQR2Q4tYok75H+qtTzKLeXyVKRVu1Ydzc3w9+dhz4iw8lsDWnhInhkelVmRlsq0mury/6y\n+7mckH27DOQh0jguhka2V2VmtOXD34dTSPtVZ/j7fInQ6u6hj8hwMltDcnkUxPV+NkKGaHZV\n5kdbKtLhktS7E7IHuQ75uH/oAzKczNaQSIKKRDToFIurMlPaYpGan9uVX7/fzLu7aqh2kXpU\nie+RvVWZL40P9kUn9Pii4JG5VZkxDZEiLz/oS9+hkTTc1qrMmoZIcRff41GfXcIxtSrzpiFS\n1KWn9cjUqsychkgxF57YI0urMncaIsVceGKPLK3K3GmIFHHZN564/i+mayJ5ZGhVZk9DpIjL\nDuxt1Bw6xs6qzJ6GSPEWHXrX9nWrUjz4iaaZqmmIFGexfbZ83cyNw76naaVqGiJFWWrvXufr\n+oAo4NtYWJWF0BApxkL7374ZaA5aKIgUYZkDh0HlNwctGESSX6RDpPpoiCS+xCGPim8OWk8Q\nSXqBgx6V3hy0viCS8PKGPSq8OWi9QSTZxY2dbS26OWj9QSTRpY1etFByc9AGgkiiSxvzqOjm\noA0EkSQXNqZR0c1BGwoiCS5r3KOCm4M2GESSW9To+zpZ3IRAU6MhktiSpnhUbHPQRoJIUgua\n5FGpzUEbewAiCS1nmkeFNgcNkcYygTZqx/DFDM/iBANNjYZIQzPd9QtLhh+FSLXTEKl3jpso\nyNTHjeBiBJoaDZH6ZrgHQQKW3D9o9APkmTQHTZqGSD3THxUJiPK0R5k0B02chkg90/tEcoOP\nmY2LE2hqNEQKT+71aPAn92bjIgWaGg2RwpNniTQfFynQ1GgpRPoqIAMiud4HJayXJA57pPDk\nIZH6HrMAFynQ1GiIdPd3a8SQR2djbqZM9Ci3zQ9NioZI5ztBY3pFmrEzusWpBJoaDZFOtz3G\nTJv8PE4n0NRoiNTe9O16wtNne5Tb5ocmRUOk9qZXkPaOkEbZbX5oUjREam/6FXHXY6Lgo2bh\nlAJNjYZI7c3ovsaFxhie9ii3zQ9NioZIx3+nvmlDJGjhINLx34kezTsJ+4jTCjQ1GiId/+2q\nMejIQo9y2/zQpGh1itRR4OvxC7sHFVliUZPd5ocmRatSpK4GX8+qscij3DY/NClajSLdiPD1\npEfD7/xGk9nmhyZFq1gkd/PHdDcQCdpjahbJNXM8GjmGGklmmx+aFK0ikS6v/o45czwKfp3Q\n1GS2+aFJ0eoR6WSL600c7F0y2/zQpGjViNQvECJBW05DJESCJkCrRaRMPMpt80OTolUiUi4e\n5bb5oUnR6hApD4kOyWzzQ5OiIRIiQROg1SpSg0jQJGl1iPRg0s2kCLzeZLb5oUnR6hAp+F4O\nkaDJ0aoQ6fb93P1kcdxQMtv80KRoNYg0sOvR9ii3zQ9NimZdpJtxhei08WS2+aFJ0YyLND7K\njUjQJGi2RQoMMUSkTUlmmx+aFM20SBM8QiRoIrR6RIpOm5TMNj80KZplkaZ4hEjQRGiGRZrk\nESJBE6HNFunN98/bbbzffLb333/dX7+HkeEgErTyaHNF+vT9Iu38MW+H+5v2/iaIDAeRoJVH\nmynSux8Qae0/mubj+ICt3/z8ZdaqteoeGc7cNeSu19A98WX3iARNgjZLpP3Gr/tF2rXWbA86\nrdpH7f0qhAxn5ho6+3KvECJBU6DNEsn7bXMRqXtAdMzW7w83e//afUYIGc68NRT2Z9QjRIIm\nQpsl0uv+qsZHexC0vc7dtHO+/fo6rXtfXiQ39H11zaBHiARNhDZ71M6f37Rtdsf3ep/3c7p7\noc+ox0gz90UzacuS2eaHJkVbKtLWfx9uvv3L/ZyuSOvTIdJvx3zJZtAjYRYh4SwVae3PGRDp\nxf/sPFN6j7Rkf8QeCZoMbalI/irS2acHkba+OxahJ9KkZyMSNAnacpE6U1qRXs4inc7C3nkk\nLdKS3dHztKXJbPNDk6ItFWnVjnV3czv8/b1Z7fqQ4YiJ5KY8HZGgSdCWivTa6rLvXAR0OiH7\ndtwR/Vytft49E5Gg2aMtH/4+nELar7pv306XCB1G6r5Xq4dn6g02THk2IkGToC0V6XD16t0J\n2YNch/yy6dcO62FQL+oeqXnWI0SCJkJbLFLzc7u6+5xE56ohH12ke3OuNk17PiJBk6CV/sG+\np9/KLaItT2abH5oUzZJIs6pBJGgSNEMizasGkaBJ0MyINLcaRIImQStcpMUeIRI0EVrZIi33\nCJGgidBsiLSgGkSCJkFDpAXPzR4HTY1WtEgC7+wQCZoIzYRIS6pBJGgSNAsiLaoGkaBJ0AyI\ntKgYRIImQitZJIl3dogETYSGSIuenTkOmhoNkRY9O3McNDWaAZGWVYNI0CRoiLTs6XnjoKnR\nEGnZ0/PGQVOjlSxSI+ARIkEToZUskoRHiARNhFawSCLv7BAJmgitXJFEBr8RCZoMDZEWPj9r\nHDQ1WrEiCXmESNBEaKWKdPkokltYDSJBk6AVKpJDJGhZ0coUySEStLxoxYu0tBpEgiZBK12k\nxdUgEjQJWpEiCXqESNBEaCWKJHiEhEjQZGjDIv39+49fL9Z//udvwZIWi+QQCVp2tEGRfj+/\nXP2fgjUhEjR7tCGR/u3c73/9uv3fL6EETZIUaXk1iARNgjYg0v+c/+t09y/n5N7d/fa1LB2P\nFi6JEKkMiPQv98fl/h/udzmRRuaPyC+4N5pAk05m/49Ck6INiOQ7U/52/xCp5xYZzkSRhKpB\nJGgStAGRbl6rYi9cRIJmkTZxj9Q4L1HOHTKcqYMNMtUgEjQJ2uAx0n8v9//r/i1UkdwJWZlq\nEAmaBG1ApL/cj8v9f8odIiESNIO0ofNIfzr/n8MA+N9//ujsnBYHkaDZow0ONgQiUJPQMZJA\nJVNowsls80OTohUmkmgho7QIyWzzQ5OilXX1t7xHiARNhFaUSMK7xhFalGS2+aFJ0RBJakE5\n4qCp0RBJakE54qCp0YoSiWMkaLnSEElsSRnioKnREElsSRnioKnRyhKpEfcIkaCJ0MoSSd4j\nRIImQitKJPk3dogETYZWkkgRjpAQCZoMDZEEl5UdDpoarUyRnFw1iARNgoZIcovKDwdNjYZI\ncovKDwdNjYZIcovKDwdNjVaSSFFGGxAJmgStJJEYtYOWLa1IkSSrQSRoErQCRZKtBpGgSdBK\nEqmJ4BEiQROhlSRSDI8QCZoIrSCRoryzQyRoIjREEl5eVjhoajREEl5eVjhoarSCROIYCVq+\ntJJEaiJ4hEjQRGhFiRQjiARNgjZbpLeBn/DbbbzffJ4et/ar7XcYGQ57JGjl0eaK9On7Rdr5\nY94O9zfHu6ufQWQ4HCNBK482U6R3PyDS2n80zcfxAe9+87P5fvUvQWQ4jNpBK482S6T9xq/7\nRdq1+6LtQae1P76ru3kwIkGzR5slkvfbqxvdA6Jjtn5/uNn71+sTVkFkOKGaDwIhErR8abNE\net1fdzIf7QHR9jp308759uvThJ+bw84pgAwnUHNrEMdI0LKlzR61O4m095vd8b3e5/2czu1l\n5m/HfD2b077ocPv0cwnRyFKRtu1B0HdnOOFOpP3mxa+6b/2e3yPFeVPXR4uazP4fhSZFWyrS\n2p9zP6czwvC98bsQMpxekaK4hEjQJGhLRfJXkc4+PYp0eAMYQobTd4wUxyREgiZBWy5SZ0or\n0stZpM3Do++Q4QyK9GSV40EkaBK0pSKt2rHubgLD3wtFcogELXPaUpFeW126791OJ2TfDmN1\nq3Ys4rMrFSJBs0dbPvx9OIW0X3WGv8+XCB1Owr75zS+Tdjf7LUSCZo+2VKTD1at3J2QPch1y\nPAm76VzA+oAMB5GglUdbLFLzc7vy6/ebed2rht7X3r/sunMXifRckROCSNAkaCV8sC+mR4gE\nTYRWlkgRqkEkaBK0okSKUQ0iQZOgIVKMheaCg6ZGQ6QYC80FB02NVpRILkI1iARNglaCSFF3\nSYgETYJWhEgNIkHLnFaGSJG+iquXFi+ZbX5oUrRSRGoieYRI0ERoxYgUyyREgiZBK0YkjpGg\n5UwrRSSutYOWNa0IkbhoFVrutBJE4upvaNnTChApqkeIBE2ElqVIt8pE9QiRoInQchTpTpqz\nReyRoOVLy1Ckh93PxSOOkaDlSitBpObiEd/ZAC1TWhEi9U9dHkSCJkHLUKT7Y6Q2iAQtZ1qO\nIrXDCsGhO/lqEAmaBC1LkS4j3teJiAQta1qWIgXOHEU7lYRI0CRoOYoUvJQBkaDlTEMk8SVm\nhIOmRstbpO5kjpGgZUzLUaSeA6IoHiESNBFaliJFcqaPppnMNj80KRoiaYFS4KCp0bIUKdLh\nUA9NNZltfmhStBxFinbyNUjTwaTBQVOjZSyS0ygGkaCJ0FKI9DWS6/D32CMJySQ57pFClwhF\nC3skaBK0LEXSNAmRoEnQ8hSpQSRoZdEyFSni5yaCNLVktvmhSdGyFUnrZBIiQZOg5StS5/KG\nmEYhEjQJWsYiXRJ134RI0CRoGYt0tifu0RIiQZOg5SvSxR9EgpY/LVuRrgPgiAQtf1r+IkX7\nsuIuTS2ZbX5oUrQSRGLUDlr2tFxFcl2RYgaRoEnQ8hcpcjWIBE2ClqNInRGG+Nc2IBI0CVqG\nInXH6uJXg0jQJGj5ieRuEr0aRIImQStApLg+IRI0CVruIkV/j4dI0CRo2Yr0IFSkIBI0CVq+\nIikdLCESNAlafiI13WMjRIJWBi1Dkb7O3nCMBK0YWq4infdJ0b+8AZGgSdAyFOnuzRwiQSuA\nlrFIrnvfxaoGkaBJ0HIWSWOsAZGgidDyE0nXI0SCJkLLTqSgRy5eNYgETYJWiEguWjWIBE2C\nhkjRlpwBDpoaLTuRtN/bIRI0CVp+IgVNilcNIkGToGUo0qFmRIJWFi1Tke5NilcNIkGToOUq\n0sGkBpGglUKbLdKb75+323i/+bz+6W8e+9yvUUT2CJGgidDmivTp+0X6Jc4hb+e/10+KdGtO\nXI8QCZoIbaZI735ApLX/aJqPywPuHzv1g306QSRoErRZIu03ft0v0q7dF20POv3K9/1jp37U\nXCeIBE2CNksk77fNRY67A6KDQfvDzd6/Hv988c8dI92LxFs7aAXQZon0um8uIn20B0Tb69xN\nO+fXnuhws/MvzTMi3Y/TMdgArQTa7FG7kxx7v9kd3+t93s853a799xyRev6UDyJBk6AtFWn7\ny5PmsPt5uZ/T3r779+uU5rdjvoZyPXfU/XPwKYQkz1KR1v6coEjt+7s5x0iu801C7JGg5U5b\nKpK/inT2qSvSi981T4oUMum50p4KIkGToC0XqTOlFenlLNLmxrMAMpyv2/0Qo3bQCqAtFWnV\njnV30x3+FhApskmIBE2CtlSk1/Zs0f6w+znldEL27TqQ9/y1drcecYwELXfa8uHvwymk/aoz\n/H2+RGh1/9gHZDjXj1Fc7vAJWWiZ05aKdLh69e6E7EGuQz4eHnuPDKfzwb4GkaCVQVssUvNz\nu/Lr95t591cNIVIiHDQ1WqYf7NMb/0YkaBK0TEW6G22IWA0iQZOgZSrSyaPI55DONMVktvmh\nSdHyFMndJGo1iARNglaCSC5mNYgETYJWhEguYjWIBE2ClqdIirskRIImQctUpOY81oBI0Iqg\n5SpSG0SCVggNkSIuOzkOmhotb5GiXyCESNBkaDmL5M5f/x2zGkSCJkHLWKTWIU7IQiuBlq9I\nKtc1IBI0GVr+Irm41SASNAlaASK5qNUgEjQJWr4iKZmESNAkaBmLpPPmDpGgSdByFknlJ14Q\nCZoELW+R4p9GQiRoIrTMRYp+GgmRoInQchcpehAJmgQNkVRpppurmoZIqjTTzVVNQyRVmunm\nqqYhkirNdHNV0xBJlWa6uappiKRKM91c1TREUqWZbq5qGiKp0kw3VzUNkVRpppurmoZIqjTT\nzVVNQyRVmunmqqalEIkQe9EXaSxje6yiY7k5ejvGRSviyVjeHqabo7djXLQinozl7WG6OXo7\nxkUrgpCK4lIXQIiFuNQFEGIhLnUBhFiIS10AIRbiUhdAiIW41AUcs9t4v/lMXYVcvn2b4x/d\n5opv9M2f7vR1VXCH595mbT0Xv77x7NrC31LXIZbPzqboNld8o5+nl1dvVwV3eOlt1tZzOkUO\nZ+0/mubj3IeBbP31/61uc6U3+n7+f7q3q3I7vPY2a+u56AWOZ9dKvj3UaSNr/32+222u8Eb3\nG78+v+Hp6arYDju9zdt6LnqJ49n6/eFm719TVyKUb7++3O82V3ij3m+b04utr6tiO+z0Nm/r\nuegljmfz2EDZ+fTbt5VfH//n6jZXeKOv++b8YuvrqtgOO73N23pOo8qRnHepJb6zDmZ7Olrd\nNrfNGWj0VHpfV0V3eNnbztl6TqHAsRS99kM5HpU2PzeHg1YzL7M2FYg0b+s5hQLHUvTaH8jO\nvxh6mbWpQKRTntx6Lmpp01L02h+KqZdZm3pEerI3F7OyiXk5V7hJW4d4Dqu825yBRk+vor6u\niu4wINL03lzMyiam2DHTsRzGd0wMDl9jdfj7kHuRntp6LnZ1E3I60/Xmy7xE6zGr9oze7jDw\n023OQKO3J2Qfuiq6w1Nv87ae06lxOKdrL1ap65DK1r98H0+WH7ZIt7nyG727ROihq5I7vOxt\n52w9p1XlUPbtwH1pl5X0Z9M29H64322u/EbPIvV1VXKH595mbT2nU+NICr72Ppz3tbkPGbS5\nHEcY/BjFpbc5W8/Fro6QGuJSF0CIhbjUBRBiIS51AYRYiEtdACEW4lIXQIiFuNQFEGIhLnUB\nhFiIS10AIRbiUhdAiIW41AUQYiEudQGEWIhLXQAhFuJSF0CIhbjUBRBiIS51AYRYiEtdACEW\n4lIXQIiFuNQFEGIhLnUBhFiIS10AIRbiUhdAiIW41AUQYiEudQGEWIhLXQAhFuJSF0CIhbjU\nBRBiIS51AYRYiEtdACEW4lIXQIiFuNQFEGIhLnUBhFiIS10AIRbiUhdAiIW41AUQYiEudQGE\nWIhLXQAhFuJSF0CIhbjUBRBiIS51AYRYiEtdACEW4lIXQIiFuNQFEGIhLnUBhFiIS10AIRbi\nUhdAiIW41AUQYiEudQGEWIhLXQAhFuJSF0CIhbjUBRBiIS51AYRYiEtdACEW4lIXQIiFOC3Q\nb4TYSwKRRuZ/qVSRhma6uappiKRKM91c1TREUqWZbq5qGiKp0kw3VzUthUhfhFgLeyRVmunm\nqqYhkirNdHNV0xBJlWa6uappiKRKM91c1TREUqWZbq5qGiKp0kw3VzUtS5GccxqFnGiqyWzz\nQ5Oi5SiSc4omIRI0CVqGIjmnaRIiQZOgIZISJwkOmhoNkZQ4SXDQ1GgZisQxErTyaDmKxKgd\ntOJoWYqkGUSCJkFDJFWa6eaqpiGSKs10c1XTEEmVZrq5qmmIpEoz3VzVNERSpZlurmoaIqnS\nTDdXNQ2RVGmmm6uahkiqNNPNVU1DJFWa6eaqpiGSKs10c1XTEEmVZrq5qmmIpEoz3VzVNERS\npZlurmoaIqnSTDdXNQ2RVGmmm6uahkiqNNPNVU1DJFWa6eaqpiGSKs10c1XTEEmVZrq5qmmI\npEoz3VzVNERSpZlurmoaIqnSTDdXNQ2RVGmmm6uahkiqNNPNVU0TEGm38X7zeTfxzbe3375N\nEBlOZmuoZBw0NdpykXatKW83Ez/P6nwiUkIcNDXacpHW/qNpPm5Uad4v6mz9/b4KkaAZpC0W\nadfui7YHnU7Zb/z6LNLaf/cjw8lsDZWMg6ZGWyzS1u8PN3v/epnk/bY5ifTt1wPIcDJbQyXj\noKnRFou0eTTmdd+cRfr027eVX390n4FI0OzRFot0fg93e5B0/nN7GmvYBpHhZLaGSsZBU6NF\nFuk4EtH83JyGHH475osQa4ks0ik7/3L9gz0SNHs0HZFu/kQkaPZoi0V6OYu0uZmMSDngoKnR\nYgx/H3IvUmcUHJGg2aNJnZB9u7uC4STSqj0fu+sO2yESNHs0sUuEVrdTL8PfL9/HSx061zcg\nEjR7tOUi7dszRcdzrtc3dOd7m3buexAZTmZrqGQcNDWa7McoHkVq3tf3H7JAJGj2aHywT5Vm\nurmqaYikSjPdXNU0RFKlmW6uahoiqdJMN1c1DZFUaaabq5qGSKo0081VTUMkVZrp5qqmIZIq\nzXRzVdMQSZVmurmqaYikSjPdXNU0RFKlmW6uahoiqdJMN1c1DZFUaaabq5qGSKo0081VTUMk\nVZrp5qqmIZIqzXRzVdMQSZVmurmqaYikSjPdXNU0RFKlmW6uahoiqdJMN1c1DZFUaaabq5qG\nSKo0081VTUMkVZrp5qqmIZIqzXRzVdMQSZVmurmqaYikSjPdXNU0RFKlmW6uahoiqdJMN1c1\nDZFUaaabq5qGSKo0081VTUMkVZrp5qqmIZIqzXRzVdMQSZVmurmqaYikSjPdXNU0RFKlmW6u\nahoiqdJMN1c1LYVIX4RYC3skVZrp5qqmIZIqzXRzVdMQSZVmurmqaYikSjPdXNU0RFKlmW6u\nahoiqdJMN1c1DZFUaaabq5qGSKo0081VTUMkVZrp5qqmIZIqzXRzVdMQSZVmurmqaYikSjPd\nXNU0RFKlmW6uahoiqdJMN1c1DZFUaaabq5qGSKo0081VTUMkVZrp5qqmIZIqzXRzVdMQSZVm\nurmqaYikSjPdXNU0RFKlmW6uahoiqdJMN1c1DZFUaaabq5qGSKo0081VTUMkVZrp5qqmIZIq\nzXRzVdMyFck5p1DJmaaYzDY/NClaniI5p2YSIkGToGUpknN6JiESNAkaIqlQEuGgqdEQSYWS\nCAdNjZalSBwjQSuNlqdIjNpBK4yWqUh6QSRoEjREUqWZbq5qGiKp0kw3VzUNkVRpppurmoZI\nqjTTzVVNExBpt/F+83k38c33zp02/D23mmeDSNAkaMtF2vlj3m4mfnrfO3fiCdmZ5TwbRIIm\nQVsu0tp/NM3HWZw27/78d2DuqEiaFzYgEjQR2mKRdu3eZnsQ5pT9xq9P6gTmIhI0g7TFIm39\n/nCz96+XSd5vm5NIgbmIBM0gbbFIm9aYb7++THrdN2eRAnM5RoJmkLZYpPPhz+1B0vnP0FxG\n7aDZo+mK9NsxX4RYS557JMWwR4ImQUMkVZrp5qqmLRbp5azK5mbyyZzQXESCZo8WY/j7kCXD\n3/MKmRlEgiZBkzoh++Zvr7a7PSF7MxeRoNmjiV0itLqdeneJUHcuIkGzR1su0r69LPV4DdB1\nTOF8rzv3ARlOZmuoZBw0NZrsxygeRZr3MQrFIBI0CRof7FOlmW6uahoiqdJMN1c1DZFUaaab\nq5qGSKo0081VTUMkVZrp5qqm9Yn097//4fy//nedezt7SRAJmj1aj0h/+fZTqv+6zL2ZvShT\nPiErBhsNIkGToPWI5N2Pv5rmzx/ux3nuzexFGRNJ8/OxiARNhhYW6Y+zQL8fhWo0RVL9xgZE\ngiZDC4v0w/33dO9P548mqYskxxsOIkGToIVF6ryM/2x3TvoiyQEHg0jQJGijIp1M0uEA9zIA\nAAujSURBVD5GQiRoRdHGRfpl0r/UR+0QCVpZtLBI/3R/dv763f2hex6JYyRopdHCIv3p/tF9\n0A/3X90TsozaQSuM1nMe6Yf78d/rX397z5UNJeKgqdH6LhH6cbNT+AuRisRBU6P1XrT65z+7\nE/7+993sBUEkaPZoXP2tSjPdXNU0RFKlmW6uahoiqdJMN1c1bVCkP/7prhGrCZGg2aMNifTD\nOUQqGgdNjTYg0p/O/Ue2mntkOJmtoZJx0NRoAyL90/0hW8wDMpzM1lDJOGhqtAGRYl2mg0jQ\n7NEQSZVmurmqaQMi+YcpMkEkaPZoAyL96+azFHJBJGj2aAMi/e/2sxRiQSRo9mhD55F+dz9i\n7JMQCZo9Wt9HzR8jVhMiQbNHQyRVmunmqqZx0aoqzXRzVdMQSZVmurmqaYikSjPdXNW0FCJ9\nEWIt7JFUaaabq5qGSKo0081VTUMkVZrp5qqmIZIqzXRzVdMQSZVmurmqaZmKxJfoQyuLlqdI\n/KwLtMJoWYqk+QNJiARNgoZIKpREOGhqNERSoSTCQVOjZSkSx0jQSqPlKRKjdtAKo2Uqkl4Q\nCZoEDZFUaaabq5qGSKo0081VTUMkVZrp5qqm5SiS3khDg0jQZGgZiqQ49t0gEjQZWn4iaZ6N\nbRAJmgwNkbRAKXDQ1GiIpAVKgYOmRstPJI6RoBVIy1AkRu2glUfLUSSVKtLQTDdXNQ2RVGmm\nm6uahkiqNNPNVU1DJFWa6eaqpiGSKs10c1XTEEmVZrq5qmmIpEoz3VzVtFxF4jsboBVFy1Qk\nvkUIWlm0PEVSvN4OkaBJ0LIUSfyH1Adpqsls80OTouUokkMkaKXRMhRJ1SNEgiZCy1kkp1EN\nIkGToCGSBiQVDpoaLUOROEaCVh5NQKTdxvvNZ8+Ub98miAyHX6OAVh5tuUi71pS38JTPOSI1\nXNkArTDacpHW/qNpPrqqdKds/ef9E7jWDpo92mKRdu2eZ3uQJzBl7b/7keFktoZKxkFToy0W\naev3h5u9fw1N+fbrAWQ4ma2hknHQ1GiLRdq07+k6xnSnfPrt28qvP7rPQCRo9miLRTofHF0P\nkrpTtqexhu2JdswXIdYSWaTjuEPzc9MdcmCPBM0eLbJIp+z8SwgZTmZrqGQcNDWajkg39xEJ\nmj3aYpFeztps+qcgUiIcNDVa5OHvc7qj4IgEzR5N6oTs23U4oTtl1Z6P3Z2H7W6R4WS2hkrG\nQVOjiV0itApO2fqXXybtN93rGxAJmj3acpH27Zmi4znX9lCoO2XT3n8PIsPJbA2VjIOmRpP9\nGMVpTKH7wYr39f2HLBAJmj1ajh/sU6kiDc10c1XTEEmVZrq5qmmIpEoz3VzVNERSpZlurmoa\nIqnSTDdXNQ2RVGmmm6uahkiqNNPNVU1DJFWa6eaqpiGSKs10c1XTEEmVZrq5qmnZisQ3rUIr\niZarSHz3N7SiaBmKdDBI79u/EQmaBC0/kVwnCtUgEjQJWnYiOUSCViAta5E0qkEkaBK0XEVi\n1A5aUbTsRNIbr2uDSNAkaPmJ1O6L+KExaEXRMhTpS/MQCZGgidAyFInBBmjl0fITiVE7aAXS\nEEkDkgoHTY2Ws0gq1SASNAlafiI1qh4hEjQRWoYifXEeCVpxtBxFUqkiDc10c1XTEEmVZrq5\nqmmIpEoz3VzVNERSpZlurmoaIqnSTDdXNQ2RVGmmm6uahkiqNNPNVU1DJFWa6eaqpiGSKs10\nc1XTEEmVZrq5qmkpRPoixFrYI6nSTDdXNQ2RVGmmm6uahkiqNNPNVU1DJFWa6eaqpiGSKs10\nc1XTEEmVZrq5qmmIpEoz3VzVNERSpZlurmoaIqnSTDdXNQ2RVGmmm6ualq9IfEEktIJo2YrE\nL/ZBK4mWq0hqXxKJSNAkaBmKdP59JESCVg4tP5Euv3yJSNDKoWUnUuc3ZDlGglYMLVeR2CNB\nK4qGSPER6XDQ1GjZicQxErQSafmJdDoTq2USIkGToGUoUueELCJBK4SGSNEJCXHQ1GjZiqQ1\n/o1I0CRo2YrEeSRoJdFyFUnt55gRCZoELVOR9H7YHJGgSdAQSYGRDAdNjYZICoxkOGhqtExF\n4hgJWlm0XEVi1A5aUbRsReI8ErSSaNmKxJUN0EqiIVJ0QkIcNDUaIkUnJMRBU6NlKxLHSNBK\noiHS4iV0Pofohh6kdmrsmsxebJZp2YqU21s711HBDaT7+J4HxmgjnMxebCKZvCZFVzkijWXC\n1h/yZn6id9YULNJ5DWWz0jVE2m2833z2TXmc+5RIs6uamt41JL0No2zfuc1lRtNc1/PWtoJI\nO3/MW3jK49ynjpHCbY+vj+mrq7uGdLdnrpm44oZXZYEr9Mne7rJcpLX/aJoP78NTHudO/lmX\n+xZTrWBC3Oj/L4tF2rV7m+1BmMcpj3N/If+PEGtZLNLW7w83e/8amvI49+m3duWkGZ5bYkuk\nk8FX7WKRNu27tm+/Dk15nFu0SGNfBBt8yl1z8ausIZNeH3ffkbicOZDFIp0Pf66HQd0pd3N/\nO+ZrWoTal8jEiqcndUNl5bTCxtZl7FU+uHhdkVqbRpZ4GSBZ3vrCnGqYt2JGmmuuC07ZYjZ5\nXC2T1+RTWV5hODmLtKDpWKtrceaea5lc42l+T1fjLcZYoVFWq+w5skl9DCVrkQLt3TxyWos3\njx+iaaSUU6TQnqQtFunlrMomNOVx7lMiKQSRoEnQ8h3+VgoiQZOgSZ2QffOfoSmPcxEJmkWa\n2CVCq/CUx7mIBM0gbblI+/ay1OM1QO2YQndK9/4DMpzM1lDJOGhqNNmPUZwG5yQ+RqEVRIIm\nQcv2g31aQSRoEjREUqWZbq5qGiKp0kw3VzUNkVRpppurmoZIqjTTzVVNQyRVmunmqqalEIkQ\ne9EXaSxje6yiY7k5ejvGRSviyVjeHqabo7djXLQinozl7WG6OXo7xkUrgpCK4lIXQIiFuNQF\nEGIhLnUBhFiIS10AIRbiUhdAiIW41AUc8/g5wLLz3X5CeMoHHgvL2/kb1vq6KrjDc2+ztp6L\nX994Aj+nVHY+O5ti5Hejysrn+asK+7oquMNLb7O2ntMpcjiBn1MqO9vO9yeN/G5UUXk//z/d\n21W5HV57m7X1XPQCxxP6OaWys/bf57tjvxtVUPYbvz6/4enpqtgOO73N23oueonjCX2fZNHp\n/p7N2BdnFhTvt+cvuunrqtgOO73N23oueonjCf2cUtH59Nu3lV8f/+ca+92ogvK6v3xjVF9X\nxXbY6W3e1nMaVY4k9J37RWd7OlrdNuM/LlBYTqX3dVV0h5e97Zyt5xQKHEvRaz+U41Fp83Nz\nOGg18zJrU4FI87aeUyhwLEWv/YHs/Iuhl1mbCkQ65cmt56KWNi1Fr/2hmHqZtalHpCd7czEr\nm5jQzymZyGGVj/1uVGE5vYr6uiq6w4BI03tzMSubmGLHTMdyGN8xMTh8jdXh70PuRXpq67nY\n1U1I6OeUis6qPaO3Owz8jP1uVGG5PSH70FXRHZ56m7f1nE6Nwwn8nFLR2fqX7+PJ8sMWGfnd\nqMJyd4nQQ1cld3jZ287Zek6ryqEEfk6p7Gzaht4P90d+N6qwnEXq66rkDs+9zdp6TqfGkRR8\n7X0472tzHzJoczmOMPgxiktvc7aei10dITXEpS6AEAtxqQsgxEJc6gIIsRCXugBCLMSlLoAQ\nC3GpCyDEQlzqAgixEJe6AEIsxKUugBALcakLIMRCXOoCCLEQl7oAQizEpS6AEAtxqQsgxEJc\n6gIIsRCXugBCLMSlLoAQC3GpCyDEQlzqAgixEJe6AEIsxKUugBALcakLIMRCXOoCCLEQl7oA\nQizEpS6AEAtxqQsgxEJc6gIIsRCXugBCLMSlLoAQC3GpCyDEQlzqAgixEJe6AEIsxKUugBAL\ncakLIMRCXOoCCLEQl7oAQizEpS6AEAtxqQsgxEJc6gIIsRCXugBCLMSlLoAQC3GpCyDEQlzq\nAgixEJe6AEIs5P8BzLk6QLFUu+YAAAAASUVORK5CYII=",
      "text/plain": [
       "plot without title"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 420,
       "width": 420
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "auto <- multi_auto[[1]]\n",
    "plot_grid(\n",
    "  qplot(y = auto$path_p_est) + \n",
    "    theme_bigstatsr() + \n",
    "    geom_hline(yintercept = auto$p_est, col = \"blue\") +\n",
    "    scale_y_log10() +\n",
    "    labs(y = \"p\"),\n",
    "  qplot(y = auto$path_h2_est) + \n",
    "    theme_bigstatsr() + \n",
    "    geom_hline(yintercept = auto$h2_est, col = \"blue\") +\n",
    "    labs(y = \"h2\"),\n",
    "  ncol = 1, align = \"hv\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "vietnamese-commodity",
   "metadata": {},
   "outputs": [],
   "source": [
    "beta_auto <- sapply(multi_auto, function(auto) auto$beta_est)\n",
    "pred_auto <- big_prodMat(G, beta_auto, ind.row = ind.test, ind.col = ind.chr2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "organic-capital",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc <- apply(pred_auto, 2, sd)\n",
    "keep <- abs(sc - median(sc)) < 3 * mad(sc)\n",
    "final_beta_auto <- rowMeans(beta_auto[, keep])\n",
    "final_pred_auto <- rowMeans(pred_auto[, keep])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "colonial-smart",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       ".dl-inline {width: auto; margin:0; padding: 0}\n",
       ".dl-inline>dt, .dl-inline>dd {float: none; width: auto; display: inline-block}\n",
       ".dl-inline>dt::after {content: \":\\0020\"; padding-right: .5ex}\n",
       ".dl-inline>dt:not(:first-of-type) {padding-left: .5ex}\n",
       "</style><dl class=dl-inline><dt>Mean</dt><dd>0.669286618800011</dd><dt>2.5%</dt><dd>0.573230813199625</dd><dt>97.5%</dt><dd>0.759024382480265</dd><dt>Sd</dt><dd>0.0475611142010799</dd></dl>\n"
      ],
      "text/latex": [
       "\\begin{description*}\n",
       "\\item[Mean] 0.669286618800011\n",
       "\\item[2.5\\textbackslash{}\\%] 0.573230813199625\n",
       "\\item[97.5\\textbackslash{}\\%] 0.759024382480265\n",
       "\\item[Sd] 0.0475611142010799\n",
       "\\end{description*}\n"
      ],
      "text/markdown": [
       "Mean\n",
       ":   0.6692866188000112.5%\n",
       ":   0.57323081319962597.5%\n",
       ":   0.759024382480265Sd\n",
       ":   0.0475611142010799\n",
       "\n"
      ],
      "text/plain": [
       "      Mean       2.5%      97.5%         Sd \n",
       "0.66928662 0.57323081 0.75902438 0.04756111 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "AUCBoot(final_pred_auto, y[ind.test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "vertical-berry",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"dataframe\">\n",
       "<caption>A matrix: 2 × 6 of type dbl</caption>\n",
       "<thead>\n",
       "\t<tr><th></th><th scope=col>used</th><th scope=col>(Mb)</th><th scope=col>gc trigger</th><th scope=col>(Mb)</th><th scope=col>max used</th><th scope=col>(Mb)</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>Ncells</th><td> 2409400</td><td>128.7</td><td>  4449390</td><td> 237.7</td><td>  4449390</td><td> 237.7</td></tr>\n",
       "\t<tr><th scope=row>Vcells</th><td>54658055</td><td>417.1</td><td>161324136</td><td>1230.9</td><td>251908186</td><td>1922.0</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A matrix: 2 × 6 of type dbl\n",
       "\\begin{tabular}{r|llllll}\n",
       "  & used & (Mb) & gc trigger & (Mb) & max used & (Mb)\\\\\n",
       "\\hline\n",
       "\tNcells &  2409400 & 128.7 &   4449390 &  237.7 &   4449390 &  237.7\\\\\n",
       "\tVcells & 54658055 & 417.1 & 161324136 & 1230.9 & 251908186 & 1922.0\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A matrix: 2 × 6 of type dbl\n",
       "\n",
       "| <!--/--> | used | (Mb) | gc trigger | (Mb) | max used | (Mb) |\n",
       "|---|---|---|---|---|---|---|\n",
       "| Ncells |  2409400 | 128.7 |   4449390 |  237.7 |   4449390 |  237.7 |\n",
       "| Vcells | 54658055 | 417.1 | 161324136 | 1230.9 | 251908186 | 1922.0 |\n",
       "\n"
      ],
      "text/plain": [
       "       used     (Mb)  gc trigger (Mb)   max used  (Mb)  \n",
       "Ncells  2409400 128.7   4449390   237.7   4449390  237.7\n",
       "Vcells 54658055 417.1 161324136  1230.9 251908186 1922.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "TRUE"
      ],
      "text/latex": [
       "TRUE"
      ],
      "text/markdown": [
       "TRUE"
      ],
      "text/plain": [
       "[1] TRUE"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Some cleaning\n",
    "rm(corr); gc(); file.remove(paste0(tmp, \".sbk\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "taken-garage",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "We have seen how to run 3 versions of LDpred2 (“-inf”, “-grid” and “-auto”) for one chromosome.\n",
    "\n",
    "Note that we now recommend to run LDpred2 genome-wide, contrary to what was shown in the first versions of this tutorial. The only difference it makes is when building the SFBM (the sparse LD matrix on disk), you need to build it so that it contains all variants genome-wide (see e.g. [this code](https://github.com/privefl/paper-ldpred2/blob/master/code/run-ldpred2-gwide.R#L39-L64)).\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.0.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
