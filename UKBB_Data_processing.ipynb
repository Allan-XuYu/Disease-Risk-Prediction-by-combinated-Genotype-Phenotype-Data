{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1) extract eid, ethnicity feature(three times instances) from main dataset .csv into .npy\n",
    "+ [UKB Data-Field 21000](https://biobank.ndph.ox.ac.uk/showcase/field.cgi?id=21000)\n",
    "+ Output file name is the column index value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import csv\n",
    "import sys\n",
    "\n",
    "# csv.field_size_limit(sys.maxsize)  # python3 do not need this\n",
    "\n",
    "n_participants = 502506 # number of individuals for ukb41910 dataset,including header\n",
    "\n",
    "ukb_char_ethnic = 9747 # 21000-0.0\n",
    "ukb_relation_participants = 10007 # 22021-0.0\n",
    "\n",
    "def save_data(dir_save, names, data):\n",
    "    if not os.path.exists(dir_save): # create file save path \n",
    "        os.makedirs(dir_save) \n",
    "    if type(names) is list:  # store to be multi-files\n",
    "        for i, name in enumerate(names):\n",
    "            np.save(os.path.join(dir_save, str(name)), data[i])\n",
    "    else:\n",
    "        np.save(os.path.join(dir_save, str(names)), data)\n",
    "    \n",
    "def get_data(dir_file, names):\n",
    "    # Get the data of item names for all individuals\n",
    "    # return the data list if names is char; a list containing data lists if names is a list\n",
    "    \n",
    "    if type(names) is list:\n",
    "        data = [[] for i in names]\n",
    "    else:\n",
    "        data = []\n",
    "    \n",
    "    inds = names # get_ind(dir_file, names)\n",
    "        \n",
    "    with open(dir_file, 'r') as csvfile:\n",
    "        reader = csv.reader(csvfile, delimiter=',')\n",
    "        for i, row in enumerate(reader):\n",
    "            if np.mod(i, 10000) == 0:   # precessed progression  \n",
    "                print('Processed data:',i)\n",
    "            if type(names) is list:\n",
    "                for j, ind in enumerate(inds):\n",
    "                    #print(str(len(row))+'\\t'+str(ind))\n",
    "                    data[j].append(row[ind])\n",
    "            else:\n",
    "                data.append(row[inds])\n",
    "    return data\n",
    "\n",
    "def generate_data(dir_file, dir_save, names):\n",
    "    names_new = []\n",
    "    # only generate data which are not generated before\n",
    "    for name in names:\n",
    "        if not os.path.isfile(os.path.join(dir_save, str(name)) + '.npy'):\n",
    "            names_new.append(name)\n",
    "            \n",
    "    # if all items are generated before\n",
    "    if not names_new:\n",
    "        return\n",
    "    data_new = get_data(dir_file, names_new)\n",
    "    save_data(dir_save, names_new, data_new)\n",
    "\n",
    "# multi-columns data    \n",
    "def generate_Matrixdata(dir_file, dir_save, names , filename):\n",
    "    names_new = []\n",
    "    # only generate data which are not generated before\n",
    "    for name in names:\n",
    "        if not os.path.isfile(os.path.join(dir_save, str(name)) + '.npy'):\n",
    "            names_new.append(name)\n",
    "            \n",
    "    # if all items are generated before\n",
    "    if not names_new:\n",
    "        return\n",
    "    data_new = get_data(dir_file, names_new)\n",
    "    save_data(dir_save, filename, data_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "function off\n"
     ]
    }
   ],
   "source": [
    "names=[0,ukb_char_ethnic,ukb_char_ethnic+1,ukb_char_ethnic+2,ukb_relation_participants]   # column index \n",
    "\n",
    "dir_save = 'C:\\\\data\\\\processed'\n",
    "dir_file = 'C:\\\\data\\\\ukbb\\\\ukb41910\\\\ukb41910.csv'\n",
    "\n",
    "if False:  \n",
    "    generate_data(dir_file,dir_save,names)\n",
    "    \n",
    "else:\n",
    "    print('function off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2) Identify white british participants\n",
    "+ ethnical background column in ukb41910 is 9747-9749\n",
    "+ Using [UKB Data-Coding 1001](https://biobank.ndph.ox.ac.uk/showcase/coding.cgi?id=1001)\n",
    "+ remove the participants who have kinship to other participants\n",
    "+ [Data-Field 22021](https://biobank.ndph.ox.ac.uk/showcase/field.cgi?id=22021) using [Data-Coding 682](https://biobank.ndph.ox.ac.uk/showcase/coding.cgi?id=682)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "function off\n"
     ]
    }
   ],
   "source": [
    "if False:    \n",
    "    all_person_id = np.load('C:\\\\data\\\\processed\\\\0.npy')\n",
    "    col_ethnic_0 = np.load('C:\\\\data\\\\processed\\\\9747.npy')\n",
    "    col_ethnic_1 = np.load('C:\\\\data\\\\processed\\\\9748.npy')\n",
    "    col_ethnic_2 = np.load('C:\\\\data\\\\processed\\\\9749.npy')\n",
    "    col_kinship = np.load('C:\\\\data\\\\processed\\\\10007.npy')\n",
    "    #merge three columns and filter first column\n",
    "    individual=all_person_id[1:] # [0] is header, ignore it\n",
    "    ethnics=col_ethnic_0[1:]  \n",
    "    col_kinship =col_kinship[1:]\n",
    "    \n",
    "    for i in range(n_participants-1):  #  -1 coz n_participants including header\n",
    "        if ethnics[i]=='' and col_ethnic_1[i+1]!='':\n",
    "            ethnics[i]=col_ethnic_1[i+1]\n",
    "    for i in range(n_participants-1):\n",
    "        if ethnics[i]=='' and col_ethnic_2[i+1]!='':\n",
    "            ethnics[i]=col_ethnic_2[i+1]\n",
    "    outfile=open('C:\\\\data\\\\processed\\\\extract_ind','w') \n",
    "    for i in range(n_participants-1):\n",
    "        if (ethnics[i]=='1001' or ethnics[i]=='2001' or ethnics[i]=='3001' or ethnics[i]=='4001') and col_kinship[i]=='0':\n",
    "            outfile.write(individual[i]+'\\n')\n",
    "    outfile.close()\n",
    "\n",
    "else:\n",
    "    print('function off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Remove withdraw participant data\n",
    "> remove the withdraw data from extract_ind file  \n",
    "outputFile :merge_white_Britich_clean , storing the eid of available participants."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "function off\n"
     ]
    }
   ],
   "source": [
    "if False:\n",
    "    extract_ind = open('C:\\\\data\\\\processed\\\\extract_ind','r')\n",
    "    path_withdraw = 'C:\\\\data\\\\ukbb\\\\ukb41910\\\\w60434_20210201.csv'\n",
    "\n",
    "    withdarw_eid = []\n",
    "    remain_eid = []\n",
    "    with open(path_withdraw, 'r') as csvfile:\n",
    "        reader = csv.reader(csvfile, delimiter=',')\n",
    "        for i, row in enumerate(reader):   # the type of row is list\n",
    "            withdarw_eid.append((int)(row[0]))  # the element of list row is str \n",
    "\n",
    "    for line in extract_ind:\n",
    "        if (int)(line) not in withdarw_eid :  \n",
    "            remain_eid.append((int)(line))  # remain eid into new list\n",
    "\n",
    "    outfile = open('C:\\\\data\\\\processed\\\\merge_white_Britich_clean','w') \n",
    "    for i in range(len(remain_eid)):\n",
    "        outfile.write(str(remain_eid[i])+'\\n')\n",
    "    outfile.close()\n",
    "else:\n",
    "    print('function off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3) Data extracting from main dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ Sex using [Data-Coing 9](https://biobank.ndph.ox.ac.uk/showcase/coding.cgi?id=9)\n",
    "+ Smoke & Alcohol using [Data-Coding 90](https://biobank.ndph.ox.ac.uk/showcase/coding.cgi?id=90)\n",
    "+ Vascular/heart problems using [Data-Coding 100605](https://biobank.ndph.ox.ac.uk/showcase/coding.cgi?id=100605)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### extract from maindata set into single column .npy file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# personal\n",
    "ukb_char_sex = 22  # 31-0.0\n",
    "ukb_char_birth = 23  # 34-0.0  year of birth\n",
    "ukb_char_bmi = 9750  # 21001-0.0\n",
    "ukb_char_weight = 9754  #21002\n",
    "ukb_char_ageRecr = 9798  #21022 age at recruitment \n",
    "# food intake\n",
    "ukb_intake_water = 758  # 1528-0.0\n",
    "ukb_intake_coffee =750  # 1508-0.0\n",
    "\n",
    "# physical activity\n",
    "ukb_phys_moderate = 526 # 884-0.0\n",
    "ukb_phys_vigorous = 534 # 904-0.0\n",
    "\n",
    "# not good life-style \n",
    "ukb_smoke_status =  8843 # 20116-0.0\n",
    "ukb_alcohol_status =  8847 # 20117-0.0\n",
    "\n",
    "# relevant diseases\n",
    "ukb_diag_vas = 6031 # 6150-0.0  Vascular/heart problems, 1:heart attack; 3:Stroke; 4:High Blood \n",
    "\n",
    "# diagnosis\n",
    "ukb_diag_diabete=1049 # 2443-0.0 diabetes\n",
    "\n",
    "# Non-cancer code self-repoted\n",
    "ukb_ill_code_start = 6696 # 20002-0.0\n",
    "ukb_ill_code_end = 6831 # \n",
    "\n",
    "# cancer code self-repoted\n",
    "ukb_cancer_code_start = 6672 # 20001-0.0\n",
    "ukb_cancer_code_end = 6695 # \n",
    "\n",
    "# date of recruitment\n",
    "ukb_date_recruitment = 89 # 53-0.0\n",
    "\n",
    "# summary\n",
    "extract_col=[ukb_char_sex,ukb_char_birth,ukb_char_ageRecr,\n",
    "             ukb_char_bmi,ukb_char_bmi+1,ukb_char_bmi+2,ukb_char_bmi+3,\n",
    "             ukb_char_weight,ukb_char_weight+1,ukb_char_weight+2,ukb_char_weight+3,\n",
    "             ukb_intake_water,ukb_intake_water+1,ukb_intake_water+2,ukb_intake_water+3,\n",
    "             ukb_intake_coffee,ukb_intake_coffee+1,ukb_intake_coffee+2,ukb_intake_coffee+3,\n",
    "             ukb_phys_moderate,ukb_phys_moderate+1,ukb_phys_moderate+2,ukb_phys_moderate+3,\n",
    "             ukb_phys_vigorous,ukb_phys_vigorous+1,ukb_phys_vigorous+2,ukb_phys_vigorous+3,\n",
    "             ukb_smoke_status,ukb_smoke_status+1,ukb_smoke_status+2,ukb_smoke_status+3,\n",
    "             ukb_alcohol_status,ukb_alcohol_status+1,ukb_alcohol_status+2,ukb_alcohol_status+3,\n",
    "             ukb_diag_diabete,ukb_diag_diabete+1,ukb_diag_diabete+2,ukb_diag_diabete+3,\n",
    "             ukb_diag_vas,ukb_diag_vas+1,ukb_diag_vas+2,ukb_diag_vas+3,\n",
    "             ukb_diag_vas+4,ukb_diag_vas+5,ukb_diag_vas+6,ukb_diag_vas+7,\n",
    "             ukb_diag_vas+8,ukb_diag_vas+9,ukb_diag_vas+10,ukb_diag_vas+11,\n",
    "             ukb_date_recruitment,ukb_date_recruitment+1,ukb_date_recruitment+2,ukb_date_recruitment+3\n",
    "            ]\n",
    "\n",
    "extract_disease = np.arange(ukb_cancer_code_start,ukb_ill_code_end+1,1)  # self-reported cancer/non-cancer diseases\n",
    "if True: # features \n",
    "    path_data = dir_file\n",
    "    path_save = 'C:\\\\data\\\\processed\\\\DataSplit'\n",
    "    generate_data(path_data,path_save,extract_col)\n",
    "    \n",
    "if True: # self-reported disease data\n",
    "    generate_data(path_data,path_save,extract_disease)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate information of self-reported disease/cancers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ Diabetes diagnosed by doctor   [Data-Field 2443](https://biobank.ndph.ox.ac.uk/showcase/field.cgi?id=2443)\n",
    "+ value using [Data-Coding 100349](https://biobank.ndph.ox.ac.uk/showcase/coding.cgi?id=100349)\n",
    "+ Description: Has a doctor ever told you that you have diabetes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "not using this record\n"
     ]
    }
   ],
   "source": [
    "if False:\n",
    "    # diagnosis by doctor ->medical condition \n",
    "    diabete_mainset = np.load('C:\\\\data\\\\processed\\\\DataSplit\\\\'+str(ukb_diag_diabete)+'.npy')\n",
    "    diabete_mainset = diabete_mainset.reshape(len(diabete_mainset),1)\n",
    "    #print(diabete_mainset)\n",
    "else:\n",
    "    print('not using this record')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process self-reported disease/cancer information from .npy files derive from .csv main dataset "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ Non-cancer self-reported illness information [Data-Field 20002](https://biobank.ctsu.ox.ac.uk/crystal/field.cgi?id=20002)\n",
    "+ using[Data-Coding 6](https://biobank.ctsu.ox.ac.uk/crystal/coding.cgi?id=6)\n",
    "+ Cancer self-reported illness information [Data-Field 20001](https://biobank.ndph.ox.ac.uk/showcase/field.cgi?id=20001)\n",
    "+ using[Data-Coding 3](https://biobank.ndph.ox.ac.uk/showcase/coding.cgi?id=3)\n",
    "\n",
    "> OutPUT file. These files cover all participants:\n",
    ">> .data file -index is not eid. Cover all participants in main dataset,Access by index of participants in mainset   \n",
    ".list file -the odd of key(disease name) is same with the rows odd of .data file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "function off\n"
     ]
    }
   ],
   "source": [
    "if False:\n",
    "    from collections import defaultdict\n",
    "\n",
    "    outdata1=open('C:\\\\data\\\\processed\\\\self_cancer.data','w')\n",
    "    outdata2=open('C:\\\\\\data\\\\processed\\\\self_disease.data','w')\n",
    "\n",
    "    outlist1=open('C:\\\\data\\\\processed\\\\self_cancer.list','w')\n",
    "    outlist2=open('C:\\\\data\\\\processed\\\\self_disease.list','w')\n",
    "\n",
    "    cancer=defaultdict(list) # the value of dict is a list\n",
    "    disease=defaultdict(list)\n",
    "    disease_map ={'1223': 'Type2 diabetes', '1471': 'atrial fibrillation','1461':'inflammatory bowel disease','1075':'myocardial infarction'}\n",
    "    cancer_map ={'1002':'breast cancer'}\n",
    "\n",
    "    for i in range(ukb_cancer_code_start,ukb_cancer_code_end+1):\n",
    "\n",
    "        col=np.load('C:\\\\data\\\\processed\\\\DataSplit\\\\'+str(i)+'.npy') # loop self-reported cancer columns\n",
    "\n",
    "        for j in range(1,n_participants): \n",
    "            if col[j] in ['1002']:   # brast cancer  , \n",
    "                cancer[cancer_map[col[j]]].append(j-1)\n",
    "\n",
    "    for i in range(ukb_ill_code_start,ukb_ill_code_end+1):\n",
    "\n",
    "        col=np.load('C:\\\\data\\\\processed\\\\DataSplit\\\\'+str(i)+'.npy') # loop self-reported non-cancer columns\n",
    "\n",
    "        for j in range(1,n_participants):  # index start from 1\n",
    "            if col[j] in ['1223','1471','1461','1075']:   \n",
    "                disease[disease_map[col[j]]].append(j-1) \n",
    "    print('finished')\n",
    "\n",
    "\n",
    "    for key,value in cancer.items():\n",
    "        sum_num=0\n",
    "        for i in range(n_participants-1): # index start from 0\n",
    "            if i in value:  # participant index in record? \n",
    "                sum_num+=1\n",
    "                outdata1.write('1'+'\\t')\n",
    "            else:\n",
    "                outdata1.write('0'+'\\t')\n",
    "        outdata1.write('\\n')\n",
    "        outlist1.write(key+'\\t')\n",
    "        outlist1.write(str(sum_num)+'\\n')\n",
    "\n",
    "    outdata1.close()\n",
    "    outlist1.close()   \n",
    "\n",
    "\n",
    "    for key,value in disease.items():\n",
    "        sum_num=0\n",
    "        for i in range(n_participants-1):\n",
    "            if i in value:   # value list may have repeated num, but dosent matter.\n",
    "                sum_num+=1\n",
    "                outdata2.write('1'+'\\t')\n",
    "            else:\n",
    "                outdata2.write('0'+'\\t')\n",
    "        outdata2.write('\\n')\n",
    "        outlist2.write(key+'\\t')\n",
    "        outlist2.write(str(sum_num)+'\\n')\n",
    "\n",
    "    outdata2.close()\n",
    "    outlist2.close() \n",
    "else:\n",
    "    print('function off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove inappropriate participants from the self-reported patients"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ merge_white_Britich_clean,  obtain available participant's eid\n",
    "+ 0.npy,eid->index in mainset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> inputFile: merge_white_Britich_clean , 0.npy  \n",
    "ouputFile: remain_eid_index.npy ,storing the index of avaliable participants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "function off\n"
     ]
    }
   ],
   "source": [
    "if False:\n",
    "    remain_eid = open('C:\\\\data\\\\processed\\\\merge_white_Britich_clean','r')\n",
    "    mainset_eid = np.load('C:\\\\data\\\\processed\\\\0.npy')\n",
    "\n",
    "    # eid mactching index of main dataset \n",
    "    individual = mainset_eid[1:].tolist() # ignore header\n",
    "    ind_index = []\n",
    "    count = 0\n",
    "    for line in remain_eid:\n",
    "        ind=line.split()[0]  # obtain remain patients eid\n",
    "        ind_index.append(individual.index(ind))# remain patients eid transform to be index of mainset\n",
    "        count+=1\n",
    "        if np.mod(count, 10000) == 0:   # precessed progression  \n",
    "            print('Processed data:',count) \n",
    "    remain_eid.close()\n",
    "\n",
    "    # store remain_index to file remain_eid_index\n",
    "\n",
    "    np.save('C:\\\\data\\\\processed\\\\remain_eid_index', np.array(ind_index)) # .npy\n",
    "\n",
    "    eid_index = open('C:\\\\data\\\\processed\\\\remain_eid_index','w')   # file\n",
    "    for i in ind_index:\n",
    "        eid_index.write(str(i)+'\\n')\n",
    "    eid_index.close()\n",
    "else:\n",
    "    print('function off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ Using the remaining patients' index to generate remaining self-reported cancer/disease files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300868\n"
     ]
    }
   ],
   "source": [
    "if False:\n",
    "    ind_genetics_index=np.load('C:\\\\data\\\\processed\\\\remain_eid_index.npy') # saving time for repeated operation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300868\n"
     ]
    }
   ],
   "source": [
    "if False:\n",
    "    infile_cancer=open('C:\\\\data\\\\processed\\\\self_cancer.data','r')\n",
    "    infile_disease=open('C:\\\\data\\\\processed\\\\self_disease.data','r')\n",
    "    outfile_cancer=open('C:\\\\data\\\\processed\\\\self_cancer_sub.data','w')\n",
    "    outfile_disease=open('C:\\\\data\\\\processed\\\\self_disease_sub.data','w')\n",
    "    outfile_cancer_num=open('C:\\\\data\\\\processed\\\\cancer_num','w')\n",
    "    outfile_disease_num=open('C:\\\\data\\\\processed\\\\disease_num','w')\n",
    "    \n",
    "\n",
    "    for line in infile_cancer:\n",
    "        A=line.strip().split()\n",
    "        sum_num=0\n",
    "        for XX in ind_genetics_index:  \n",
    "            outfile_cancer.write(A[XX]+'\\t')\n",
    "            sum_num=sum_num+int(A[XX])\n",
    "        outfile_cancer_num.write(str(sum_num)+'\\n')\n",
    "        outfile_cancer.write('\\n')\n",
    "\n",
    "    for line in infile_disease:\n",
    "        A=line.strip().split()\n",
    "        sum_num=0\n",
    "        for XX in ind_genetics_index:\n",
    "            outfile_disease.write(A[XX]+'\\t')\n",
    "            sum_num=sum_num+int(A[XX])\n",
    "        outfile_disease_num.write(str(sum_num)+'\\n')\n",
    "        outfile_disease.write('\\n')\n",
    "    infile_cancer.close()\n",
    "    infile_disease.close()\n",
    "    outfile_cancer.close()\n",
    "    outfile_disease.close()\n",
    "    outfile_cancer_num.close()\n",
    "    outfile_disease_num.close()\n",
    "else:\n",
    "    print('function off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Process hes_diag to genereate cancer/disease information from hospitalization records"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ICD-10 code\n",
    "\n",
    "+ E11.X - type2 diabetes\n",
    "+ I21.X,I22.X,I23.X,I24.1,I25.2 - CAD\n",
    "+ I48.X - atrial fibrillation\n",
    "+ K51.X - inflammatory bowel\n",
    "+ C50.X - breast cancer  \n",
    "\n",
    "Reference: Khera, A.V., Chaffin, M., Aragam, K.G. et al. Genome-wide polygenic scores for common diseases identify individuals with risk equivalent to monogenic mutations. Nat Genet 50, 1219â€“1224 (2018). https://doi.org/10.1038/s41588-018-0183-z\n",
    "#### hes_diag have not diagnosis date ,  we capture the eid and instance index as key to match from hesin file to get date information in the following step\n",
    ">OutputFile:   \n",
    "1)hes_t2d_eid_ins.npy, has two columns-> T2D patients' eid & ins_index   \n",
    "2)hes_CAD_eid_ins.npy  \n",
    "3)hes_IBD_eid_ins.npy  \n",
    "4)hes_AF_eid_ins.npy  \n",
    "5)hes_BC_eid_ins.npy  \n",
    "Those .npy files are already remove inapplicable participants by below preprocessed subfile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> InputFile:  \n",
    "1)hesin_diag.txt  \n",
    "2)merge_white_Britich_clean, flitering the inapplicable participants by subeid record"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "function off\n"
     ]
    }
   ],
   "source": [
    "if False:\n",
    "    import re\n",
    "    from collections import defaultdict\n",
    "    disease=defaultdict(list)\n",
    "    hesdiag_file=open('C:\\\\data\\\\ukbb\\HES\\\\record-level hospital inpatient data tables\\\\hesin_diag.txt','r')\n",
    "    \n",
    "    t2d_ins = []\n",
    "    t2d_eid = []\n",
    "    CAD_ins = []\n",
    "    CAD_eid = []\n",
    "    AF_ins = []\n",
    "    AF_eid = []\n",
    "    IBD_ins = []\n",
    "    IBD_eid = []\n",
    "    BC_ins = []\n",
    "    BC_eid = []\n",
    "    \n",
    "    count=0\n",
    "    # A[3] is level column ; A[6] is ICD-10 code ;A[0] is eid\n",
    "    for line in hesdiag_file:\n",
    "        A = line.strip('\\n').split('\\t') # to be a string list\n",
    "\n",
    "        eid = A[0]\n",
    "        ins_index = A[1]\n",
    "        level = A[3]    \n",
    "        ICD10 = A[6]\n",
    "        if level == '1': \n",
    "            if re.match(r'E11*', ICD10):\n",
    "                disease['type2 diabetes'].append(eid)\n",
    "                t2d_eid.append(eid)\n",
    "                t2d_ins.append(ins_index)\n",
    "                \n",
    "            if re.match(r'I21*', ICD10) or re.match(r'I22*', ICD10) or re.match(r'I23*', ICD10) or re.match(r'I241', ICD10) or re.match(r'I252', ICD10):\n",
    "                disease['myocardial infarction'].append(eid)\n",
    "                CAD_eid.append(eid)\n",
    "                CAD_ins.append(ins_index)\n",
    "            \n",
    "            if re.match(r'I48*', ICD10):\n",
    "                disease['atrial fibrillation'].append(eid)\n",
    "                AF_eid.append(eid)\n",
    "                AF_ins.append(ins_index)\n",
    "                \n",
    "            if re.match(r'K51*', ICD10):\n",
    "                disease['inflammatory bowel disease'].append(eid)\n",
    "                IBD_eid.append(eid)\n",
    "                IBD_ins.append(ins_index)\n",
    "                \n",
    "            if re.match(r'C50*', ICD10):\n",
    "                disease['breast cancer'].append(eid)\n",
    "                BC_eid.append(eid)\n",
    "                BC_ins.append(ins_index)\n",
    "                \n",
    "        count+=1\n",
    "        if np.mod(count, 100000) == 0: \n",
    "            print('Process:',count)\n",
    "\n",
    "    hesdiag_file.close()\n",
    "    print('finished disease_dic')\n",
    "\n",
    "# for macthing diagnosed date\n",
    "    # load subeid file\n",
    "    remain_eid = open('C:\\\\data\\\\processed\\\\merge_white_Britich_clean','r')\n",
    "    sub_eid=[]\n",
    "    for line in remain_eid:\n",
    "        A=line.split()[0]\n",
    "        sub_eid.append(A)\n",
    "    remain_eid.close()\n",
    "    \n",
    "    remain_t2d_eid=[]\n",
    "    remain_t2d_ins=[]\n",
    "    for i in range(len(t2d_eid)):\n",
    "        if t2d_eid[i] in sub_eid:\n",
    "            remain_t2d_eid.append(t2d_eid[i])\n",
    "            remain_t2d_ins.append(t2d_ins[i])\n",
    "    remain_t2d_eid = np.array(remain_t2d_eid)\n",
    "    remain_t2d_ins = np.array(remain_t2d_ins)\n",
    "    t2d_eid_ins=np.concatenate((remain_t2d_eid.reshape(len(remain_t2d_eid),1),remain_t2d_ins.reshape(len(remain_t2d_ins),1)),axis =1)\n",
    "    np.save('C:\\\\data\\\\processed\\\\hes_t2d_eid_ins', t2d_eid_ins)\n",
    "    print('finished saving HES-T2D patient eid and ins_index')\n",
    "    remain_CAD_eid=[]\n",
    "    remain_CAD_ins=[]\n",
    "    for i in range(len(CAD_eid)):\n",
    "        if CAD_eid[i] in sub_eid:\n",
    "            remain_CAD_eid.append(CAD_eid[i])\n",
    "            remain_CAD_ins.append(CAD_ins[i])\n",
    "    remain_CAD_eid = np.array(remain_CAD_eid)\n",
    "    remain_CAD_ins = np.array(remain_CAD_ins)\n",
    "    CAD_eid_ins=np.concatenate((remain_CAD_eid.reshape(len(remain_CAD_eid),1),remain_CAD_ins.reshape(len(remain_CAD_ins),1)),axis =1)\n",
    "    np.save('C:\\\\data\\\\processed\\\\hes_CAD_eid_ins', CAD_eid_ins)\n",
    "    print('finished saving HES-CAD patient eid and ins_index')\n",
    "    remain_AF_eid=[]\n",
    "    remain_AF_ins=[]\n",
    "    for i in range(len(AF_eid)):\n",
    "        if AF_eid[i] in sub_eid:\n",
    "            remain_AF_eid.append(AF_eid[i])\n",
    "            remain_AF_ins.append(AF_ins[i])\n",
    "    remain_AF_eid = np.array(remain_AF_eid)\n",
    "    remain_AF_ins = np.array(remain_AF_ins)\n",
    "    AF_eid_ins=np.concatenate((remain_AF_eid.reshape(len(remain_AF_eid),1),remain_AF_ins.reshape(len(remain_AF_ins),1)),axis =1)\n",
    "    np.save('C:\\\\data\\\\processed\\\\hes_AF_eid_ins', AF_eid_ins)\n",
    "    print('finished saving HES-AF patient eid and ins_index')\n",
    "    remain_IBD_eid=[]\n",
    "    remain_IBD_ins=[]\n",
    "    for i in range(len(IBD_eid)):\n",
    "        if IBD_eid[i] in sub_eid:\n",
    "            remain_IBD_eid.append(IBD_eid[i])\n",
    "            remain_IBD_ins.append(IBD_ins[i])\n",
    "    remain_IBD_eid = np.array(remain_IBD_eid)\n",
    "    remain_IBD_ins = np.array(remain_IBD_ins)\n",
    "    IBD_eid_ins=np.concatenate((remain_IBD_eid.reshape(len(remain_IBD_eid),1),remain_IBD_ins.reshape(len(remain_IBD_ins),1)),axis =1)\n",
    "    np.save('C:\\\\data\\\\processed\\\\hes_IBD_eid_ins', IBD_eid_ins)\n",
    "    print('finished saving HES-IBD patient eid and ins_index')\n",
    "    remain_BC_eid=[]\n",
    "    remain_BC_ins=[]\n",
    "    for i in range(len(BC_eid)):\n",
    "        if BC_eid[i] in sub_eid:\n",
    "            remain_BC_eid.append(BC_eid[i])\n",
    "            remain_BC_ins.append(BC_ins[i])\n",
    "    remain_BC_eid = np.array(remain_BC_eid)\n",
    "    remain_BC_ins = np.array(remain_BC_ins)\n",
    "    BC_eid_ins=np.concatenate((remain_BC_eid.reshape(len(remain_BC_eid),1),remain_BC_ins.reshape(len(remain_BC_ins),1)),axis =1)\n",
    "    np.save('C:\\\\data\\\\processed\\\\hes_BC_eid_ins', BC_eid_ins)\n",
    "    print('finished saving HES-BC patient eid and ins_index')\n",
    "    \n",
    "#  Generate one-hot format diseases diagonsis information for available participants by HES_diag   \n",
    "    outdata1=open('C:\\\\data\\\\processed\\\\ICD10_HES.data','w')\n",
    "    outlist1=open('C:\\\\data\\\\processed\\\\ICD10_HES.list','w')\n",
    "    mainset_eid = np.load('C:\\\\data\\\\processed\\\\0.npy') \n",
    "    \n",
    "    eid = mainset_eid[1:]\n",
    "    for key,value in disease.items():\n",
    "        sum_num=0\n",
    "        print(key)\n",
    "        for i in range(n_participants-1): # index start from 0\n",
    "            if eid[i] in value:  \n",
    "                sum_num+=1\n",
    "                outdata1.write('1'+'\\t')\n",
    "            else:\n",
    "                outdata1.write('0'+'\\t')\n",
    "            if np.mod(i, 10000) == 0: \n",
    "                print('Process: ',i)\n",
    "        outdata1.write('\\n')\n",
    "        outlist1.write(key+'\\t')\n",
    "        outlist1.write(str(sum_num)+'\\n')\n",
    "\n",
    "    outdata1.close()\n",
    "    outlist1.close() \n",
    "\n",
    "else:\n",
    "    print('function off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ Using the remaining patients' index to generate remaining hes ICD10 diagnosis files\n",
    "> Output file:\n",
    ">> ICD10_HES_sub.data, every row represents one disease from three digits ICD10 code main diagnosis   \n",
    "ICD10_HES_num, remaining avaliable inpatients diagnosis information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "    sub_index=np.load('C:\\\\data\\\\processed\\\\remain_eid_index.npy') # saving time for repeated operation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "function off\n"
     ]
    }
   ],
   "source": [
    "if False:\n",
    "    infile_disease=open('C:\\\\data\\\\processed\\\\ICD10_HES.data','r')\n",
    "    outfile_disease=open('C:\\\\data\\\\processed\\\\ICD10_HES_sub.data','w')\n",
    "    outfile_disease_num=open('C:\\\\data\\\\processed\\\\ICD10_HES_num','w')\n",
    "\n",
    "    for line in infile_disease:\n",
    "        A=line.strip().split()\n",
    "        sum_num=0\n",
    "        for XX in sub_index:\n",
    "            outfile_disease.write(A[XX]+'\\t')\n",
    "            sum_num=sum_num+int(A[XX])\n",
    "        outfile_disease_num.write(str(sum_num)+'\\n')\n",
    "        outfile_disease.write('\\n')\n",
    "        \n",
    "    infile_disease.close()\n",
    "    outfile_disease.close()\n",
    "    outfile_disease_num.close()\n",
    "else:\n",
    "    print('function off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Integrate Hes_diag & self-reported diag information to generate Testing cases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ Patients who not be diagnosed at recruitment, but be diagnosed in inpatient record\n",
    "+ Using pandas date format(Timestamp) for time comparasion, ignoring those inpatient record before recruitment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">OutputFiles:  \n",
    "1) eid_testCAD.npy ,the eid of patients those as testing set  \n",
    "2) eid_testT2D.npy  \n",
    "3) eid_testAF.npy  \n",
    "4) eid_testIBD.npy  \n",
    "5) eid_testBC.npy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "    import pandas as pd\n",
    "\n",
    "    col_recruiment_0 = np.load('C:\\\\data\\\\processed\\\\DataSplit\\\\89.npy')\n",
    "    col_recruiment_1 = np.load('C:\\\\data\\\\processed\\\\DataSplit\\\\90.npy')\n",
    "    col_recruiment_2 = np.load('C:\\\\data\\\\processed\\\\DataSplit\\\\91.npy')\n",
    "    col_recruiment_3 = np.load('C:\\\\data\\\\processed\\\\DataSplit\\\\92.npy')\n",
    "    subset_index = np.load('C:\\\\data\\\\processed\\\\remain_eid_index.npy')\n",
    "\n",
    "    recruiment_date = col_recruiment_0[1:]\n",
    "    sub_recruiment_date=[]\n",
    "    for i in range(n_participants-1): \n",
    "        if recruiment_date[i]=='' and col_recruiment_1[i+1]!='':\n",
    "            recruiment_date[i]=col_recruiment_1[i+1]\n",
    "    for i in range(n_participants-1):\n",
    "        if recruiment_date[i]=='' and col_recruiment_2[i+1]!='':\n",
    "            recruiment_date[i]=col_recruiment_2[i+1]\n",
    "    for i in range(n_participants-1):\n",
    "        if recruiment_date[i]=='' and col_recruiment_3[i+1]!='':\n",
    "            recruiment_date[i]=col_recruiment_3[i+1]\n",
    "    for i in subset_index:  # remove the not applicable participants\n",
    "        sub_recruiment_date.append(recruiment_date[i])\n",
    "    sub_recruiment_date = pd.to_datetime(np.array(sub_recruiment_date), format='%Y-%m-%d') # date format transformation\n",
    "\n",
    "    # load raw hesin file & transform epistart date format\n",
    "    df=pd.read_table('C:\\\\data\\\\ukbb\\HES\\\\record-level hospital inpatient data tables\\\\hesin.txt',usecols=[0,1,4])\n",
    "    df['epistart']=pd.to_datetime(df['epistart'], format='%Y%m%d')\n",
    "    # load preprocessed file\n",
    "    hes_t2d = np.load('C:\\\\data\\\\processed\\\\hes_t2d_eid_ins.npy')\n",
    "    hes_CAD = np.load('C:\\\\data\\\\processed\\\\hes_CAD_eid_ins.npy')\n",
    "    hes_AF = np.load('C:\\\\data\\\\processed\\\\hes_AF_eid_ins.npy')\n",
    "    hes_IBD = np.load('C:\\\\data\\\\processed\\\\hes_IBD_eid_ins.npy')\n",
    "    hes_BC = np.load('C:\\\\data\\\\processed\\\\hes_BC_eid_ins.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "    from collections import defaultdict\n",
    "    disease=defaultdict(list)\n",
    "    infile1=open('C:\\\\data\\\\processed\\\\self_cancer_sub.data','r')\n",
    "    infile2=open('C:\\\\data\\\\processed\\\\self_disease_sub.data','r')\n",
    "    for line in infile1:\n",
    "        breast_cancer=line.strip().split('\\t') # do not strip'\\n', it will add one null element\n",
    "\n",
    "    disease_index = 0\n",
    "    for line in infile2:\n",
    "        disease[disease_index]=line.strip().split('\\t')\n",
    "        disease_index+=1\n",
    "\n",
    "    infile1.close()\n",
    "    infile2.close()\n",
    "\n",
    "    # load subeid file\n",
    "    remain_eid = open('C:\\\\data\\\\processed\\\\merge_white_Britich_clean','r')\n",
    "    sub_eid=[]\n",
    "    for line in remain_eid:\n",
    "        A=line.split()[0]\n",
    "        sub_eid.append(A)\n",
    "    remain_eid.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ disease dict contain four target diseases, the index of that:\n",
    "> myocardial infarction: disease[0]  \n",
    "atrial fibrillation:disease[2]   \n",
    "inflammatory bowel disease:disease[3]  \n",
    "type2 diabetes:disease[1] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "function off\n"
     ]
    }
   ],
   "source": [
    "if False:\n",
    "    testing_CAD = []\n",
    "    for i in range(len(hes_CAD)):\n",
    "        # format sorting \n",
    "        eid = (int)(hes_CAD[i][0])  # column 0 represent inpatient eid\n",
    "        ins_index = (int)(hes_CAD[i][1]) # column 1 represent inpatient instance index\n",
    "        ir_subset_index = sub_eid.index((str)(eid))\n",
    "\n",
    "        Select = df[(df['eid']==eid)&(df['ins_index']==ins_index)] # composite key as Pk searching in hesin table\n",
    "        if (Select['epistart']>sub_recruiment_date[ir_subset_index]).values[0]: # dataframe -> numpy array-> element   \n",
    "            if disease[0][ir_subset_index]=='0': # self-reported(at recruitment) is not be diagnosed\n",
    "                testing_CAD.append(eid)\n",
    "        if np.mod(i, 10000) == 0: \n",
    "            print('Process: ',i)\n",
    "        testing_CAD = list(set(testing_CAD))\n",
    "    print('Finished CAD ')\n",
    "\n",
    "    testing_t2d = []\n",
    "    for i in range(len(hes_t2d)):\n",
    "        # format sorting \n",
    "        eid = (int)(hes_t2d[i][0])  # column 0 represent inpatient eid\n",
    "        ins_index = (int)(hes_t2d[i][1]) # column 1 represent inpatient instance index\n",
    "        ir_subset_index = sub_eid.index((str)(eid))\n",
    "\n",
    "        Select = df[(df['eid']==eid)&(df['ins_index']==ins_index)] # composite key as Pk searching in hesin table\n",
    "        if (Select['epistart']>sub_recruiment_date[ir_subset_index]).values[0]: # dataframe -> numpy array-> element   \n",
    "            if disease[1][ir_subset_index]=='0': # self-reported(at recruitment) is not be diagnosed\n",
    "                testing_t2d.append(eid)\n",
    "        if np.mod(i, 10000) == 0: \n",
    "            print('Process: ',i)\n",
    "        testing_t2d = list(set(testing_t2d))\n",
    "    print('Finished t2d ')\n",
    "\n",
    "    testing_AF = []\n",
    "    for i in range(len(hes_AF)):\n",
    "        # format sorting \n",
    "        eid = (int)(hes_AF[i][0])  # column 0 represent inpatient eid\n",
    "        ins_index = (int)(hes_AF[i][1]) # column 1 represent inpatient instance index\n",
    "        ir_subset_index = sub_eid.index((str)(eid))\n",
    "\n",
    "        Select = df[(df['eid']==eid)&(df['ins_index']==ins_index)] # composite key as Pk searching in hesin table\n",
    "        if (Select['epistart']>sub_recruiment_date[ir_subset_index]).values[0]: # dataframe -> numpy array-> element   \n",
    "            if disease[2][ir_subset_index]=='0': # self-reported(at recruitment) is not be diagnosed\n",
    "                testing_AF.append(eid)\n",
    "        if np.mod(i, 10000) == 0: \n",
    "            print('Process: ',i)\n",
    "        testing_AF = list(set(testing_AF))\n",
    "    print('Finished AF ')\n",
    "\n",
    "    testing_IBD = []\n",
    "    for i in range(len(hes_IBD)):\n",
    "        # format sorting \n",
    "        eid = (int)(hes_IBD[i][0])  # column 0 represent inpatient eid\n",
    "        ins_index = (int)(hes_IBD[i][1]) # column 1 represent inpatient instance index\n",
    "        ir_subset_index = sub_eid.index((str)(eid))\n",
    "\n",
    "        Select = df[(df['eid']==eid)&(df['ins_index']==ins_index)] # composite key as Pk searching in hesin table\n",
    "        if (Select['epistart']>sub_recruiment_date[ir_subset_index]).values[0]: # dataframe -> numpy array-> element   \n",
    "            if disease[3][ir_subset_index]=='0': # self-reported(at recruitment) is not be diagnosed\n",
    "                testing_IBD.append(eid)\n",
    "        if np.mod(i, 10000) == 0: \n",
    "            print('Process: ',i)\n",
    "        testing_IBD = list(set(testing_IBD))\n",
    "    print('Finished IBD ')\n",
    "\n",
    "    testing_BC = []\n",
    "    for i in range(len(hes_BC)):\n",
    "        # format sorting \n",
    "        eid = (int)(hes_BC[i][0])  # column 0 represent inpatient eid\n",
    "        ins_index = (int)(hes_BC[i][1]) # column 1 represent inpatient instance index\n",
    "        ir_subset_index = sub_eid.index((str)(eid))\n",
    "\n",
    "        Select = df[(df['eid']==eid)&(df['ins_index']==ins_index)] # composite key as Pk searching in hesin table\n",
    "        if (Select['epistart']>sub_recruiment_date[ir_subset_index]).values[0]: # dataframe -> numpy array-> element   \n",
    "            if breast_cancer[ir_subset_index]=='0': # self-reported(at recruitment) is not be diagnosed\n",
    "                testing_BC.append(eid)\n",
    "        if np.mod(i, 10000) == 0: \n",
    "            print('Process: ',i)\n",
    "        testing_BC = list(set(testing_BC))\n",
    "    print('Finished BC ')\n",
    "\n",
    "    save_CAD = np.array(testing_CAD)\n",
    "    save_CAD.sort()\n",
    "    save_t2d = np.array(testing_t2d)\n",
    "    save_t2d.sort()\n",
    "    save_AF = np.array(testing_AF)\n",
    "    save_AF.sort()\n",
    "    save_IBD = np.array(testing_IBD)\n",
    "    save_IBD.sort()\n",
    "    save_BC = np.array(testing_BC)\n",
    "    save_BC.sort()\n",
    "    save_data('C:\\\\data\\\\processed\\\\testset','eid_testCAD', save_CAD)\n",
    "    save_data('C:\\\\data\\\\processed\\\\testset','eid_testT2D', save_t2d)\n",
    "    save_data('C:\\\\data\\\\processed\\\\testset','eid_testAF', save_AF)\n",
    "    save_data('C:\\\\data\\\\processed\\\\testset','eid_testIBD', save_IBD)\n",
    "    save_data('C:\\\\data\\\\processed\\\\testset','eid_testBC', save_BC)\n",
    "    print('all done')\n",
    "\n",
    "else:\n",
    "    print('function off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate the information of testing cases\n",
    "> OutputFiles:  \n",
    "1) eid_test_cases.npy :the eid of patients who are regarded as testing set  \n",
    "2) test_cases.list : the number of target diseases cases in testing set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "    CAD=np.load('C:\\\\data\\\\processed\\\\testset\\\\eid_testCAD.npy')\n",
    "    T2D=np.load('C:\\\\data\\\\processed\\\\testset\\\\eid_testT2D.npy')\n",
    "    AF=np.load('C:\\\\data\\\\processed\\\\testset\\\\eid_testAF.npy')\n",
    "    IBD=np.load('C:\\\\data\\\\processed\\\\testset\\\\eid_testIBD.npy')\n",
    "    BC=np.load('C:\\\\data\\\\processed\\\\testset\\\\eid_testBC.npy')\n",
    "    temp=np.concatenate((CAD,T2D,AF,IBD,BC),axis=0)\n",
    "    temp=list(set(temp)) # remove repeated eid\n",
    "    count_dict={'myocardial infarction':len(CAD),'type2 diabetes':len(T2D),'atrial fibrillation':len(AF),'inflammatory bowel disease':len(IBD),'breast cancer':len(BC),'n_test pool':len(temp)}\n",
    "    temp.sort()\n",
    "    save_data('C:\\\\data\\\\processed\\\\testset','eid_test_cases', temp)\n",
    "    outfile =open('C:\\\\data\\\\processed\\\\testset\\\\test_cases.list','w')\n",
    "    for key,value in count_dict.items():\n",
    "        outfile.write(key+'\\t'+str(value))\n",
    "        outfile.write('\\n')\n",
    "    outfile.close()\n",
    "else:\n",
    "    print('function off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Integrate self-reported diseases and ICD10-codes to generate all diag information"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ Load five diseases diagnosis information generated before\n",
    "> Inputfile: 1)self_cancer_sub.data,  2)self_diseas_sub.data,  3)ICD10_HES_sub.data  \n",
    "Outputfile: 1) Integrated_diagnosis.data 2)Integrated_diagnosis.list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "function off\n"
     ]
    }
   ],
   "source": [
    "if False:\n",
    "    from collections import defaultdict\n",
    "    HES=defaultdict(list)\n",
    "    disease=defaultdict(list)\n",
    "    infile1=open('C:\\\\data\\\\processed\\\\self_cancer_sub.data','r')\n",
    "    infile2=open('C:\\\\data\\\\processed\\\\self_disease_sub.data','r')\n",
    "    infile3=open('C:\\\\data\\\\processed\\\\ICD10_HES_sub.data','r')\n",
    "\n",
    "    for line in infile1:\n",
    "        breast_cancer=line.strip().split('\\t')\n",
    "\n",
    "    disease_index = 0\n",
    "    for line in infile2:\n",
    "        disease[disease_index]=line.strip('\\n').split('\\t')\n",
    "        disease_index+=1\n",
    "\n",
    "    HES_index = 0\n",
    "    for line in infile3:\n",
    "        HES[HES_index]=line.strip('\\n').split('\\t')  # load HES_sub data ,HES[0] is 'myocardial infarction'\n",
    "        HES_index+=1\n",
    "\n",
    "    infile1.close()\n",
    "    infile2.close()\n",
    "    infile3.close()\n",
    "else:\n",
    "    print('function off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Integrate HES and self-reported information\n",
    ">> myocardial infarction: HES[0] -> disease[0]  \n",
    "atrial fibrillation: HES[1] -> disease[2]  \n",
    "breast cancer:HES[2] -> breast_cancer  \n",
    "inflammatory bowel disease:HES[3] -> disease[3]  \n",
    "type2 diabetes:HES[4] -> disease[1] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "function off\n"
     ]
    }
   ],
   "source": [
    "if False:\n",
    "    outdata1=open('C:\\\\data\\\\processed\\\\Integrated_diagnosis.data','w')\n",
    "    outlist1=open('C:\\\\data\\\\processed\\\\Integrated_diagnosis.list','w')\n",
    "\n",
    "    for key,value in HES.items():\n",
    "        print(key)\n",
    "        sum_num = 0                 \n",
    "\n",
    "        for j in range(len(breast_cancer)): # avaliable record num - 453663\n",
    "            if key==0:\n",
    "                condition = ( HES[key][j] == '1' or disease[0][j]=='1')\n",
    "            elif key==1:\n",
    "                condition = ( HES[key][j] == '1' or disease[2][j]=='1')\n",
    "            elif key==2:\n",
    "                condition = ( HES[key][j] == '1' or breast_cancer[j]=='1')\n",
    "            elif key==3:\n",
    "                condition = ( HES[key][j] == '1' or disease[3][j]=='1')\n",
    "            elif key==4:\n",
    "                condition = ( HES[key][j] == '1' or disease[1][j]=='1')\n",
    "\n",
    "            if condition:\n",
    "                sum_num+=1\n",
    "                outdata1.write('1'+'\\t')\n",
    "            else:\n",
    "                outdata1.write('0'+'\\t')\n",
    "\n",
    "            if np.mod(j, 100000) == 0: \n",
    "                print('Process: ',j)\n",
    "        outdata1.write('\\n')\n",
    "        outlist1.write(str(sum_num)+'\\n')\n",
    "\n",
    "    outdata1.close()\n",
    "    outlist1.close()\n",
    "else:\n",
    "    print('function off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate controls pool&cases set without test cases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Outputfile:\n",
    ">>1)control_pool: the eid of all controls  \n",
    "2)control_pool_num: the number of controls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [],
   "source": [
    "if True:\n",
    "    from collections import defaultdict\n",
    "    disease=defaultdict(list)\n",
    "    infile=open('C:\\\\data\\\\processed\\\\Integrated_diagnosis.data','r')\n",
    "    infile2=open('C:\\\\data\\\\processed\\\\merge_white_Britich_clean','r')\n",
    "    test_pool=np.load('C:\\\\data\\\\processed\\\\testset\\\\eid_test_cases.npy')\n",
    "    index_to_eid=[]\n",
    "    disease_index=0\n",
    "    \n",
    "    for line in infile2:\n",
    "        A=line.strip().split('\\t')[0]\n",
    "        sub_eid.append(A)\n",
    "    infile2.close()\n",
    "    for line in infile: \n",
    "        A=line.strip().rsplit()\n",
    "        disease[disease_index]=A\n",
    "        disease_index+=1\n",
    "    infile.close()\n",
    "    \n",
    "    outfile1=open('C:\\\\data\\\\processed\\\\control_pool','w')\n",
    "    outfile2=open('C:\\\\data\\\\processed\\\\control_pool_num','w')\n",
    "    control_index=[]\n",
    "    case_flag=False\n",
    "    for i in range(len(disease[0])): \n",
    "\n",
    "        for j in range(5): # diagnosed anyone of those five diseases\n",
    "            if disease[j][i]=='1':\n",
    "                case_flag=True\n",
    "                \n",
    "\n",
    "        if not case_flag: # controls \n",
    "            if (int)(sub_eid[i]) not in test_pool:\n",
    "                control_index.append(i)\n",
    "\n",
    "        case_flag=False \n",
    "\n",
    "    n_control_pool = len(control_index)\n",
    "    outfile2.write(str(n_control_pool)+'\\n')\n",
    "    for i in control_index:\n",
    "        outfile1.write(sub_eid[i]+'\\n')\n",
    "\n",
    "    outfile1.close()\n",
    "    outfile2.close()\n",
    "else:\n",
    "    print('function off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
